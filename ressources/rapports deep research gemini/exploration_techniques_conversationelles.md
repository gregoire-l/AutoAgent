# **Exploration des Techniques Conversationnelles Avancées pour la Clarification de Mission dans AutoAgent**

## **I. Introduction**

### **Le Défi : Concilier Collecte Structurée et Conversation Fluide dans AutoAgent**

Les systèmes d'intelligence artificielle (IA) conversationnelle, en particulier les agents conçus pour des tâches complexes, sont confrontés à un défi fondamental : comment interagir de manière naturelle et engageante tout en accomplissant des objectifs internes précis et structurés? Ce dilemme est au cœur de la problématique rencontrée par le projet AutoAgent V1, un système multi-agents développé en Go et React. Un composant clé, l'agent Orchestrateur, interagit avec l'utilisateur via une interface de Chat pour définir les objectifs, le contexte, les contraintes et les livrables d'une nouvelle mission avant son lancement.

La difficulté réside dans la nécessité de trouver un équilibre délicat. D'une part, l'Orchestrateur doit collecter un ensemble spécifique d'informations, guidé par une checklist interne, pour garantir la fiabilité et la complétude de la définition de la mission. D'autre part, l'interaction doit être perçue par l'utilisateur comme une conversation fluide, naturelle et adaptative, évitant l'impression de suivre un script rigide, de répondre à un formulaire déguisé ou de se répéter inutilement. L'objectif est de minimiser la friction cognitive et de rendre l'expérience utilisateur aussi "intelligente" et productive que possible.1 Gérer cette tension entre la structure interne requise pour la fiabilité du système et la fluidité externe attendue pour une expérience utilisateur optimale est essentiel pour le succès de l'Orchestrateur d'AutoAgent.

### **Objectifs et Structure du Rapport**

Ce rapport vise à réaliser une exploration approfondie et rigoureuse des techniques, modèles, principes scientifiques et meilleures pratiques permettant de concevoir la logique conversationnelle de l'agent Orchestrateur d'AutoAgent. L'objectif est de lui permettre de mener un dialogue de clarification d'exigences de manière adaptative, engageante et efficace, en conciliant la structure interne et la fluidité externe.

La recherche s'appuie sur les avancées en Interaction Homme-Machine (IHM), Conception Conversationnelle (CxD), Traitement Automatique du Langage Naturel (TALN), Psychologie Cognitive et IA Conversationnelle, en se basant sur des sources académiques et expertes reconnues.3

Le rapport est structuré comme suit :

1. **Fondations : Compréhension de l'Input Utilisateur et Simulation de l'Écoute Active :** Analyse des techniques TALN pour extraire l'information pertinente et des méthodes pour simuler une écoute active naturelle.  
2. **Moteur Principal : Stratégies de Gestion de Dialogue Adaptatif :** Exploration des modèles permettant d'adapter dynamiquement le dialogue au-delà des scripts fixes, incluant le suivi de l'état du dialogue (DST) et l'apprentissage par renforcement (RL).  
3. **Orchestration du Flux : Gestion des Dynamiques Conversationnelles :** Étude des stratégies pour équilibrer l'initiative et gérer les tours de parole et les interruptions.  
4. **Conception Centrée sur l'Humain : Application des Principes de Communication et de Cognition :** Intégration des maximes conversationnelles, de la théorie de la politesse et des contraintes cognitives pour une interaction plus naturelle et engageante.  
5. **Combler le Fossé : Architectures pour la Structure et la Fluidité :** Examen des patrons de conception permettant de concilier la checklist interne et la flexibilité externe.  
6. **Apprendre de la Pratique : Études de Cas et Bonnes Pratiques :** Analyse d'exemples concrets et synthèse des meilleures pratiques émergentes.  
7. **Recommandations Actionnables pour AutoAgent V1 :** Formulation de conseils spécifiques pour la conception de l'Orchestrateur.  
8. **Conclusion :** Synthèse des résultats et perspectives.

## **II. Fondations : Compréhension de l'Input Utilisateur et Simulation de l'Écoute Active**

Pour qu'un agent conversationnel comme l'Orchestrateur puisse mener un dialogue de clarification efficace, il doit d'abord être capable de comprendre précisément ce que dit l'utilisateur et de lui montrer qu'il a compris. Cela repose sur des techniques avancées de Traitement Automatique du Langage Naturel (TALN) pour l'analyse de l'input et des stratégies pour simuler une écoute active convaincante.

### **TALN Avancé pour l'Extraction d'Informations**

La première étape cruciale est l'analyse sémantique de l'énoncé de l'utilisateur en langage naturel. Il ne s'agit pas simplement de repérer des mots-clés, mais de saisir le sens profond, l'intention et les détails spécifiques pertinents pour la checklist interne de l'Orchestrateur.8 Plusieurs composants de la Compréhension du Langage Naturel (NLU \- Natural Language Understanding) sont essentiels à cet égard.

* **Reconnaissance d'Intention (Intent Recognition/Classification) :** Il s'agit d'identifier le but ou l'objectif principal de l'utilisateur dans son message.8 Par exemple, l'utilisateur cherche-t-il à définir un objectif de mission, à énoncer une contrainte, à poser une question, ou à confirmer une information? La reconnaissance précise de l'intention est fondamentale pour guider le gestionnaire de dialogue vers la réponse ou l'action appropriée.8 Cette tâche est souvent modélisée conjointement avec le remplissage de slots 12 et intégrée dans des architectures modulaires ou end-to-end.16 Un défi particulier est la gestion des énoncés contenant plusieurs intentions.14  
* **Extraction d'Entités (Entity Extraction / Named Entity Recognition \- NER) :** Cette technique vise à repérer et à classifier des éléments d'information spécifiques dans le texte, tels que des noms de projets, des dates limites, des technologies mentionnées, des montants budgétaires, des noms de parties prenantes, etc..8 L'extraction d'entités est essentielle pour peupler automatiquement la checklist interne de l'Orchestrateur avec les détails fournis par l'utilisateur.  
* **Remplissage de Slots (Slot Filling) :** Le remplissage de slots consiste à extraire les valeurs correspondant aux paramètres prédéfinis (les "slots") requis par la checklist de l'Orchestrateur.9 Par exemple, extraire la valeur "analyser les retours clients" pour le slot objectif=, "budget \< 10k€" pour contrainte\_type=budget, ou "rapport PDF" pour livrable\_format=. C'est une tâche centrale en NLU pour les systèmes orientés tâche 20, souvent modélisée conjointement avec la détection d'intention pour améliorer la performance.12  
* **Gestion de l'Information Implicite et Flexibilité :** Un défi majeur réside dans le fait que les utilisateurs ne formulent pas toujours l'information de manière explicite, structurée ou dans l'ordre attendu par le système.16 L'information peut être implicite, dispersée sur plusieurs tours de parole, ou nécessiter une inférence. Les systèmes de dialogue doivent donc faire preuve de flexibilité au-delà du simple remplissage de slots rigide.16  
  * *Zero-Shot Slot Filling :* L'utilisation de grands modèles de langage (LLM) pour le remplissage de slots sans entraînement spécifique (zero-shot) est une piste prometteuse, mais présente des défis dans les contextes conversationnels dynamiques avec changements de sujet et références implicites.23 Des techniques pour améliorer cette approche incluent l'utilisation de descriptions de slots, d'exemples 23, la distillation de connaissances (Knowledge Distillation \- KD) à partir de modèles plus grands, et l'ajustement fin basé sur des instructions (instruction fine-tuning).24  
  * *Induction de Slots (Slot Induction) :* Plutôt que de dépendre uniquement de schémas de slots prédéfinis, l'induction de slots (ou Slot Schema Induction \- SSI) vise à découvrir automatiquement les types d'informations pertinents (les slots) à partir de données de dialogue non étiquetées.26 Des approches génératives comme GenDSI prédisent conjointement les noms et les valeurs des slots 26, tandis que des méthodes comme RCAP utilisent un processus en trois étapes (Role-labeling, Concept-mining, Pattern-mining).33 Cette capacité permettrait à l'Orchestrateur d'identifier potentiellement des aspects importants de la mission non prévus dans la checklist initiale, augmentant ainsi sa flexibilité et sa couverture.  
* **Résolution de Coréférence :** Il est crucial de résoudre les références pronominales ("il", "cela", "ça") et autres expressions référentielles ("l'objectif précédent", "cette contrainte") qui renvoient à des entités ou concepts mentionnés plus tôt dans l'historique du dialogue.18 Des modèles comme CDST modélisent explicitement la coréférence pour le suivi de l'état du dialogue (DST).36 La conscience du contexte est fondamentale 38, car les références implicites sont un défi majeur dans les données conversationnelles.23 L'incapacité à résoudre correctement ces références mène à des incompréhensions et brise la fluidité de la conversation.  
* **Compréhension Sémantique :** Au-delà de l'extraction, des techniques d'analyse sémantique plus profondes, comme le parsing sémantique 30, la sémantique des cadres (frame semantics) 12, ou l'analyse de sentiment 8, peuvent aider à interpréter les nuances du sens voulu par l'utilisateur.

L'efficacité de ces techniques est régulièrement présentée et évaluée dans des conférences majeures en TALN comme EMNLP et ACL.3

### **Techniques pour Simuler une Écoute Active Naturelle**

Une clarification d'exigences efficace ne se limite pas à extraire passivement des informations. L'agent doit activement démontrer qu'il écoute, comprend et s'engage dans la conversation, à l'instar d'un interlocuteur humain pratiquant l'écoute active.46 Cela permet de construire un rapport de confiance et encourage l'utilisateur à fournir des informations plus complètes et précises.

Les comportements clés de l'écoute active humaine incluent le maintien de l'attention, la reformulation, la pose de questions de clarification, le résumé, l'utilisation d'accusés de réception verbaux et non verbaux (ex: "Hum hum", "Je vois", hochements de tête), la manifestation d'empathie, la suspension du jugement et l'évitement des interruptions inopportunes.48 Transposer ces comportements dans un agent conversationnel nécessite des techniques spécifiques pour éviter un rendu robotique.

* **Reformulation et Paraphrase Non Robotiques :**  
  * *Objectif :* Confirmer la compréhension, valider l'information et assurer l'alignement sans paraître répétitif ou mécanique.11  
  * *Techniques :* Diverses approches existent pour générer des paraphrases variées tout en préservant le sens 11 :  
    * *Paraphrase Dense (Dense Paraphrasing \- DP) :* Vise à enrichir textuellement l'énoncé en résolvant les ambiguïtés contextuelles ou en explicitant la sémantique sous-jacente, par exemple en remplaçant une référence vague comme "celui-là" par "le bloc bleu".56 Cela peut impliquer la résolution d'anaphores, la saturation de cadres sémantiques, la décomposition d'événements ou le suivi d'états d'entités.57  
    * *Transfert de Style via Paraphrase (STRAP) :* Utilise des modèles de paraphrase diversifiés et des modèles inverses spécifiques à un style pour reformuler une phrase.60  
    * *Pipelines Automatisés :* Combinaison de techniques comme la traduction pivot (aller-retour vers une autre langue), la supervision faible (remplacement de mots), ou l'utilisation de modèles Transformer pour générer des candidats.45  
  * *Éviter le Robotisme :* L'accent doit être mis sur la *reformulation contextuelle*, liée à la tâche en cours, plutôt que sur la simple répétition (écho) de l'énoncé de l'utilisateur.53 Il est essentiel d'utiliser un phrasé varié et d'éviter les modèles génériques et répétitifs.  
* **Questions de Clarification Contextuelles :**  
  * *Objectif :* Résoudre les ambiguïtés, combler les manques d'information et sonder pour une compréhension plus approfondie.52  
  * *Ciblées vs. Génériques :* Il faut contraster les questions génériques inefficaces ("Pouvez-vous répéter?") avec des questions ciblées qui identifient précisément le problème de compréhension.52 Certains systèmes peuvent même poser proactivement des questions de clarification lorsqu'une ambiguïté est détectée.55  
  * *Techniques 53 :*  
    * *Demandes de Clarification Partielles :* Ne clarifier que la partie incomprise (ex: "Deux personnes?", "Qui?").  
    * *Questions Alternatives :* Proposer explicitement des choix pour résoudre une ambiguïté (ex: "Denilson ou Edilson?", "Junior ou Senior?").  
    * *Reformulations au Niveau de la Tâche :* Reformuler l'information en fonction de ses implications pour la tâche (ex: "Vous voulez donc que je passe au-dessus du charpentier?").  
* **Résumé Progressif (Progressive Summarization) :**  
  * *Objectif :* Synthétiser périodiquement les informations recueillies pour confirmer la compréhension mutuelle, gérer la charge cognitive de l'utilisateur (en rafraîchissant sa mémoire) et donner un sentiment de progression, ce qui est particulièrement important dans des dialogues de clarification potentiellement longs.10  
  * *Technique :* Le concept de "Résumé Progressif" ou "Résumé Adaptatif" implique une mise à jour incrémentale du résumé existant plutôt qu'une regénération complète à chaque fois.66 Cela maintient la cohérence 66 et évite la surcharge d'information.73 Il se distingue des approches classiques d'extraction ou d'abstraction.67 Des prompts spécifiques peuvent guider un LLM pour *affiner* le résumé existant en fonction des nouveaux éléments de la conversation.66  
  * *Lisibilité Instantanée ("Glanceability") :* L'objectif est de rendre ces résumés facilement "scannables" pour en saisir l'essentiel rapidement, sans noyer l'utilisateur dans les détails.63  
* **Accusés de Réception et Feedback Contextuels :**  
  * *Technique :* Utiliser des accusés de réception courts et pertinents ("OK, compris.", "Entendu.", "C'est logique.") et, si l'interface le permet, des signaux non verbaux simulés (comme un hochement de tête 51) pour indiquer l'attention et la compréhension.50 Des outils IA peuvent même fournir un feedback sur les compétences d'écoute simulées.48 Le concept japonais d'*Aizuchi* illustre bien cette idée de "backchanneling" via des sons, des hochements de tête et de courtes reformulations.51

L'efficacité des techniques d'écoute active simulée, telles que la reformulation contextuelle 53 ou la clarification ciblée 52, dépend intrinsèquement de la capacité du système à comprendre précisément l'input utilisateur. Pour poser une question de clarification pertinente, l'agent doit d'abord identifier le point d'ambiguïté ou l'information manquante grâce à une NLU robuste.8 De même, la génération d'un résumé progressif 66 nécessite une extraction et un suivi précis des informations clés au fil des tours de parole (Suivi de l'état du dialogue, abordé en Section III). Cette interdépendance souligne que l'investissement dans des capacités NLU/DST sophistiquées est essentiel non seulement pour la collecte de données fiable, mais aussi pour la création d'une expérience conversationnelle perçue comme naturelle et engageante par l'utilisateur d'AutoAgent.

On observe une tendance nette à dépasser la simple détection de mots-clés et les modèles rigides pour s'orienter vers des approches plus flexibles, génératives et adaptatives, tant pour la compréhension 23 que pour la génération de réponses.11 Cette évolution reflète l'influence croissante des LLMs et le désir d'interactions homme-IA plus naturelles. Les systèmes antérieurs reposaient largement sur des slots et des templates prédéfinis.12 Les recherches actuelles explorent des techniques visant à gérer les inputs imprévus, à réduire la création manuelle de schémas et à générer des sorties plus variées et contextuelles. Cela suggère qu'AutoAgent devrait explorer ces méthodes plus récentes, potentiellement via des LLMs ou des modèles affinés, pour atteindre une plus grande flexibilité et naturalité, tout en restant conscient des défis que posent les LLMs pour les tâches structurées.23

Un thème récurrent est la difficulté pour les systèmes de dialogue de traiter l'information qui n'est pas explicitement énoncée, que ce soit par le biais de coréférences 36 ou de significations implicites.23 La gestion de cet implicite est critique pour une conversation fluide et humaine. Des modèles comme CDST 36, les défis du remplissage de slots zero-shot 23, la gestion des références implicites 37, et la Paraphrase Dense pour lever l'ambiguïté 56 illustrent tous cette problématique. Les humains gèrent cela naturellement, mais l'IA peine. Ne pas résoudre les coréférences ou comprendre l'intention implicite conduit à des malentendus et interrompt le flux conversationnel. Cela implique que la NLU et la gestion de dialogue d'AutoAgent doivent intégrer des mécanismes spécifiquement conçus pour traiter les références implicites et inférer le sens au-delà des mots littéraux afin d'atteindre la naturalité souhaitée.

## **III. Moteur Principal : Stratégies de Gestion de Dialogue Adaptatif**

Au cœur de l'Orchestrateur se trouve le gestionnaire de dialogue, responsable du maintien du contexte, du suivi de l'état de la conversation et de la décision de la prochaine action ou question du système. Pour passer d'un script rigide à une conversation adaptative, des stratégies de gestion de dialogue plus sophistiquées sont nécessaires, s'appuyant fortement sur un suivi précis de l'état du dialogue (Dialogue State Tracking \- DST).

### **Suivi de l'État du Dialogue (DST) : Modèles, Techniques et Défis**

Le DST est le composant qui maintient la compréhension par le système des objectifs de l'utilisateur et de l'historique de la conversation, généralement sous forme de paires slot-valeur.6 Il est fondamental car il informe directement les décisions de la politique de dialogue en aval.7

* **Évolution du DST :** Les approches ont évolué depuis les systèmes basés sur des règles 6 et les modèles génératifs (comme les POMDP \- Partially Observable Markov Decision Processes) 7 vers des modèles discriminatifs.6 Aujourd'hui, les approches neuronales et d'apprentissage profond dominent 7, en particulier la génération texte-à-texte utilisant des modèles de langage pré-entraînés (PLM) ou des LLM.7  
* **Techniques de DST :**  
  * *Basées sur la Classification :* Traitent le DST comme une classification multi-classes basée sur des ontologies fixes.76  
  * *Séquence-à-Séquence (Seq2Seq) / Texte-à-Texte :* Génèrent directement la représentation de l'état à partir de l'historique du dialogue.7 L'ajustement fin basé sur des instructions (instruction tuning) est une technique utilisée pour les LLM appliqués au DST.77  
  * *Approches Hybrides :* Combinaison de méthodes, par exemple, en décidant dynamiquement entre prédire une distribution complète sur les valeurs possibles ou extraire des candidats de l'historique.31  
  * *Gestion de la Coréférence :* Des modèles comme CDST prédisent explicitement les slots/valeurs coréférencés 36, tandis que TripPy modélise implicitement les relations de coréférence via des mécanismes de copie.36  
* **Défis Clés du DST** 7 **:**  
  * *Variation Linguistique :* Gérer les synonymes et les paraphrases.75  
  * *Dynamique Multi-tours :* Inférer l'état à partir du contexte sur plusieurs tours.75  
  * *Valeurs Hors Vocabulaire (OOV) / Hors Domaine (OOD) :* Traiter les valeurs non vues à l'entraînement.36 Les techniques d'extraction basées sur le contexte 36 et les approches zero-shot/few-shot 7 tentent d'y remédier.  
  * *Manque de Données et Coût d'Annotation :* Nécessité de grands corpus annotés.36  
  * *Propagation d'Erreurs :* Les erreurs de la NLU ou de la reconnaissance vocale (ASR) impactent le DST.7  
  * *Généralisabilité et Robustesse :* Difficulté des modèles à s'adapter à de nouveaux domaines, à des changements de distribution ou à des concepts inconnus.7  
  * *Raisonnement Multi-étapes :* Performance réduite lorsque plusieurs étapes de raisonnement sont nécessaires.76

Des ressources comme les Dialog State Tracking Challenges (DSTC) 6 et des surveys dédiés 6 fournissent des cadres d'évaluation et des revues des techniques existantes.

### **Apprentissage de Politiques Adaptatives : Au-delà des Scripts Fixes**

L'objectif est de dépasser les flux conversationnels rigides et prédéfinis pour permettre à l'Orchestrateur d'adapter dynamiquement sa stratégie en fonction de l'état du dialogue, de l'input utilisateur et du contexte global.

* **Limitations des Approches Fixes** 69 **:** Les automates à états finis (Finite State Machines \- FSM) et les systèmes basés sur des règles offrent clarté, contrôle et simplicité pour les tâches basiques.83 Cependant, ils manquent de flexibilité, peinent à s'adapter à la complexité croissante (explosion d'états), gèrent difficilement les inputs inattendus et peuvent aboutir à des interactions rigides et peu naturelles.83  
* **Modèles de Gestion de Dialogue Adaptatifs** 88 **:**  
  * *Concept :* Systèmes qui ajustent leur comportement en fonction des caractéristiques du dialogue, de modèles utilisateur ou du contexte.90 L'adaptation peut se baser sur le niveau de compétence de l'utilisateur, sa connaissance du domaine, son empressement 90, ou son intention prédite.89  
  * *Approches Neuronales 89 :* Utilisation de réseaux de neurones pour modéliser l'intention de l'utilisateur (prédire le prochain acte de dialogue) en fonction de l'historique et du profil utilisateur. Le gestionnaire de dialogue (également neuronal) utilise cette prédiction en temps réel pour sélectionner l'action système optimale, permettant une adaptation dynamique.  
  * *Logique Floue / Règles Floues 91 :* Application de règles floues et de clustering d'intentions pour une gestion adaptative, potentiellement utile pour gérer l'ambiguïté.  
  * *Adaptation Basée sur les LLM 88 :* Exploration de l'utilisation des LLM pour la gestion adaptative du dialogue, en adaptant les énoncés en fonction de paramètres comme le sentiment, le groupe d'âge 88, ou en utilisant le prompting pour une génération contrôlable basée sur les intentions/stratégies de dialogue.92  
* **Apprentissage par Renforcement (RL) pour l'Apprentissage de Politique de Dialogue (DPL)** 17 **:**  
  * *Cadre :* Formulation de la gestion de dialogue comme un problème de décision séquentielle (MDP/POMDP) où l'agent apprend une politique optimale (mappage états vers actions) pour maximiser une récompense à long terme (satisfaction utilisateur, complétion de tâche).93  
  * *Avantages :* Potentiel d'optimisation automatique des politiques dans de vastes espaces de recherche 95, gestion des inputs bruités et du comportement stochastique de l'utilisateur 95, adaptation au comportement de l'utilisateur 94, et possibilité d'améliorer les politiques conçues par des humains.98  
  * *Défis 94 :*  
    * *Conception de la Récompense :* Difficulté à spécifier des fonctions de récompense efficaces ; souvent clairsemées (récompense seulement en fin de dialogue) et différées, rendant l'apprentissage inefficace.96  
    * *Efficacité de l'Exploration :* Interaction coûteuse avec de vrais utilisateurs ; les simulateurs peuvent manquer de réalisme.103 L'exploration invalide est inefficace.106  
    * *Problème du Démarrage à Froid (Cold Start) :* Des politiques initiales médiocres mènent à de mauvaises interactions et un apprentissage lent.108  
    * *Grands Espaces État-Action :* Particulièrement dans les tâches multi-domaines.108  
    * *Interdépendance :* Négliger le lien entre la compréhension (DST) et la génération (RG/DPL) limite l'optimisation globale.96  
  * *Solutions aux Défis :*  
    * *Façonnage/Apprentissage de Récompense :* Récompenses pas-à-pas pour le DST et la génération 96 ; RL Inverse (IRL) / Guided DPL (GDPL) pour apprendre les récompenses à partir de dialogues humains, en évaluant les paires état-action pour des signaux plus denses 100 ; Apprentissage de fonctions de récompense paramétrées reflétant les préférences 101 ; Apprentissage curriculaire.110  
    * *Amélioration Exploration/Efficacité :* Utilisation de simulateurs d'utilisateurs 22, RL hors ligne (offline RL) sur des datasets statiques 96, RL basé sur mots-clés (KRLS) avec échantillonnage du mot suivant 107, enrichissement du buffer de rejeu avec des épisodes réussis.105  
    * *Démarrage à Chaud (Warm Start) :* Pré-entraînement des politiques par apprentissage supervisé.98  
    * *Optimisation Conjointe :* Conception de récompenses optimisant simultanément la compréhension (DST) et la génération (DPL/RG).96  
  * *Surveys/Revues :* Des surveys couvrent l'application du RL au DPL.22

### **Adaptation Contextuelle : Exploiter l'Historique et la Détection d'Ambigüité**

* **Importance du Contexte** 10 **:** La compréhension du contexte (historique du dialogue, état de l'utilisateur, tours précédents) est essentielle pour un dialogue adaptatif et cohérent.10 Le contexte aide à la reconnaissance d'intention, à la désambiguïsation et à la personnalisation.112  
* **Techniques de Conscience Contextuelle** 10 **:**  
  * *Suivi de l'État du Dialogue (DST) :* Maintien explicite de l'historique de la conversation.112  
  * *Bases de Données Contextuelles :* Stockage et récupération d'informations contextuelles.112  
  * *Mécanismes de Mémoire :* Stockage/rappel des interactions précédentes.116 Les LLM utilisent nativement des fenêtres de contexte, mais la mémoire à long terme reste un défi.42  
  * *Modélisation Thématique Contextuelle :* Prédiction des sujets basée sur le contexte et les actes de dialogue.114  
* **Adaptation Basée sur l'Ambigüité :** Le système peut adapter sa stratégie (par exemple, poser une question de clarification) lorsqu'un faible niveau de confiance ou une ambiguïté est détecté par la NLU ou le DST (lié à la clarification en Section II). Un changement de stratégie de dialogue peut être envisagé si le dialogue est jugé problématique.90

La qualité et la robustesse du DST 7 constituent à la fois une contrainte et un catalyseur pour l'efficacité de la gestion adaptative du dialogue. Un état de dialogue imprécis ou incomplet empêche la politique (qu'elle soit basée sur des règles, apprise ou issue du RL) de prendre des décisions optimales. Inversement, un DST précis et conscient du contexte permet des stratégies plus sophistiquées et adaptatives. Les politiques adaptatives 89 nécessitent une connaissance de la situation actuelle (besoins utilisateur, historique). Les politiques RL 94 exigent une représentation précise de l'état 105 pour apprendre des valeurs état-action ou des gradients de politique significatifs. Les défis du DST 36 se répercutent directement sur le gestionnaire de dialogue. Par conséquent, améliorer la robustesse du DST 7 est primordial pour permettre un dialogue véritablement adaptatif dans AutoAgent.

Bien que le RL offre un paradigme puissant pour optimiser les politiques de dialogue 93, la difficulté majeure réside dans la conception de fonctions de récompense qui capturent efficacement les objectifs multiples d'une bonne conversation (complétion de tâche, efficacité, naturalité, satisfaction utilisateur) et fournissent des signaux suffisamment denses pour un apprentissage efficace.96 Des récompenses binaires simples (succès/échec) sont trop clairsemées.100 Concevoir manuellement des récompenses denses est complexe et peut ne pas généraliser.100 Cela a conduit à des recherches sur les récompenses pas-à-pas 96, l'apprentissage de récompenses 100, les récompenses basées sur les préférences 101 et l'apprentissage curriculaire.110 Pour AutoAgent, l'application directe d'algorithmes RL standards est peu susceptible de fonctionner sans une conception minutieuse, voire innovante, de la fonction de récompense. Celle-ci devrait potentiellement intégrer des métriques de succès de la tâche (complétion de la checklist) et de qualité de l'interaction (fluidité, engagement utilisateur). La proposition de récompense pas-à-pas intégrant compréhension et génération 97 semble particulièrement pertinente.

Les techniques de gestion de dialogue adaptatives 88 offrent une plus grande flexibilité que les FSM/règles rigides.83 Cependant, cette flexibilité peut se faire au détriment de la prévisibilité et du contrôle, qui peuvent être cruciaux pour une collecte d'exigences fiable. Les approches basées sur les LLM, bien que fluides, peuvent "halluciner" ou s'écarter de la structure nécessaire (lié à la motivation de CALM 38). Les FSM offrent un contrôle élevé mais une faible flexibilité.83 Les politiques RL apprennent un comportement optimal mais peuvent être difficiles à interpréter ou à garantir le respect de contraintes spécifiques (éléments de la checklist) sans une conception minutieuse de la récompense. Les LLM offrent une grande fluidité mais manquent de contrôle déterministe inhérent.38 AutoAgent a besoin à la fois de flexibilité (conversation naturelle) et de contrôle (complétion fiable de la checklist). Cela suggère que des approches hybrides pourraient être nécessaires, combinant les forces de différentes techniques. Par exemple, utiliser une politique flexible (RL ou guidée par LLM) pour le flux général de la conversation, mais employer des mécanismes plus stricts (peut-être des vérifications basées sur des règles ou des prompts spécifiques) pour s'assurer que tous les éléments de la checklist sont finalement abordés et validés. Le framework CALM de Rasa 38 illustre cette pensée hybride, utilisant les LLM pour la compréhension mais des flux structurés pour l'exécution.

### **Tableau Comparatif des Approches de Gestion de Dialogue**

Le tableau suivant synthétise les caractéristiques clés des différentes approches de gestion de dialogue, en mettant en évidence leurs compromis respectifs, notamment en ce qui concerne la flexibilité et le contrôle, cruciaux

 pour le défi d'AutoAgent.

| Caractéristique | Basée sur Règles | Automate à États Finis (FSM) | Statistique/ML (ex: NNs) | Apprentissage par Renforcement (RL) | Basée sur LLM / Prompting |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Flexibilité/Adaptabilité** | Très Faible | Faible | Moyenne à Élevée 89 | Élevée (potentiellement) 94 | Très Élevée 88 |
| **Contrôle/Prévisibilité** | Élevé | Très Élevé 83 | Moyen | Faible à Moyen (dépend de la récompense) | Faible (risque d'hallucination) 38 |
| **Scalabilité** | Faible (maintenabilité) 83 | Faible (explosion d'états) 83 | Moyenne à Élevée | Moyenne (grands espaces état-action) 108 | Élevée (modèles pré-entraînés) |
| **Besoin en Données** | Faible (conception manuelle) | Faible (conception manuelle) | Élevé (supervisé) 75 | Très Élevé (exploration/offline) 101 | Variable (prompting vs fine-tuning) |
| **Interprétabilité** | Élevée | Élevée | Faible à Moyenne | Faible | Très Faible |
| **Effort Développement** | Moyen (si complexe) | Moyen (si complexe) | Élevé (entraînement modèle) | Très Élevé (conception récompense, entraînement) | Moyen à Élevé (prompting, tests) |
| **Gestion Incertitude** | Faible | Faible | Moyenne 89 | Élevée (modélisation MDP/POMDP) 95 | Moyenne (implicite dans LLM) |

Ce tableau comparatif met en lumière les compromis inhérents à chaque approche. Les méthodes traditionnelles (Règles, FSM) offrent un contrôle élevé mais manquent de flexibilité. Les approches basées sur l'apprentissage (ML, RL, LLM) offrent une plus grande adaptabilité mais posent des défis en termes de contrôle, de besoin en données et d'interprétabilité. Le choix pour AutoAgent dépendra de la priorité accordée à la fiabilité de la collecte (contrôle) par rapport à la naturalité de l'interaction (flexibilité), suggérant qu'une approche hybride pourrait offrir le meilleur équilibre.

## **IV. Orchestration du Flux : Gestion des Dynamiques Conversationnelles**

Au-delà de la compréhension de l'input et de la décision de la prochaine action, une conversation naturelle implique une gestion dynamique du flux, notamment en ce qui concerne qui contrôle la conversation (initiative) et comment les tours de parole sont gérés.

### **Stratégies pour l'Interaction à Initiative Mixte**

* **Concept d'Initiative Mixte :** Il s'agit d'une stratégie d'interaction flexible où le contrôle de la conversation peut passer de l'agent à l'utilisateur et vice-versa, de manière dynamique et opportuniste.117 Cela contraste avec les dialogues purement dirigés par le système (où l'agent pose toutes les questions) ou entièrement laissés à l'initiative de l'utilisateur (où l'utilisateur fournit toute l'information sans guide).  
* **Importance pour la Clarification :** L'initiative mixte est particulièrement pertinente pour la clarification d'exigences.92 L'Orchestrateur doit pouvoir *prendre l'initiative* pour guider l'utilisateur à travers les points de la checklist et s'assurer que toutes les informations nécessaires sont collectées.117 Simultanément, l'utilisateur doit avoir la possibilité de *prendre l'initiative* pour élaborer sur un point, poser ses propres questions, corriger l'agent ou même changer temporairement de sujet. Un équilibre est nécessaire pour que le processus soit à la fois efficace (couvrant la checklist) et naturel (permettant la flexibilité de l'utilisateur).  
* **Prise et Cession d'Initiative :** L'agent peut prendre l'initiative en posant des questions directes, en suggérant la prochaine étape ou en structurant la discussion.117 Des planificateurs de politiques peuvent prescrire des intentions ou stratégies de dialogue spécifiques pour que l'agent prenne le contrôle.92 Inversement, l'agent doit savoir quand *céder l'initiative*, par exemple en utilisant des questions ouvertes 90 ou en répondant aux questions de l'utilisateur, lui laissant ainsi l'espace pour développer sa pensée.  
* **Adaptation de l'Initiative :** Le niveau d'initiative peut être adapté dynamiquement en fonction du contexte ou de l'utilisateur.90 Par exemple, un utilisateur novice pourrait nécessiter plus de guidage (initiative système), tandis qu'un utilisateur expert pourrait préférer plus de liberté (initiative utilisateur).90 Les LLM peuvent être utilisés via prompting pour générer des réponses correspondant à une stratégie d'initiative mixte contrôlée.92

### **Gestion Efficace des Tours de Parole et des Interruptions**

* **Bases de la Prise de Tour :** La gestion des tours de parole régit qui parle et quand.116 Chez les humains, ce processus repose sur des indices complexes (intonation, regard, syntaxe).118 L'IA doit détecter les moments opportuns pour un changement de tour, souvent appelés "Points de Transition Pertinents" (Transition-Relevant Places \- TRPs).119  
* **Défis pour l'IA** 116 **:**  
  * *Latence de Réponse :* Des délais supérieurs à 600 ms peuvent perturber le flux et inciter l'utilisateur à reparler.116  
  * *Interruptions Prématurées :* L'IA interrompt l'utilisateur trop tôt, ne respectant pas les pauses naturelles.  
  * *Détection de Fin de Tour :* Difficulté à déterminer avec précision quand l'utilisateur a fini de parler, en distinguant les pauses de la cession de tour.119 La simple Détection d'Activité Vocale (VAD) est souvent insuffisante.119  
  * *Gestion des Chevauchements :* Différencier les interruptions intentionnelles des signaux de feedback (backchannels) ou du bruit.119  
* **Stratégies pour une Prise de Tour Fluide** 116 **:**  
  * *Minimiser la Latence :* Optimiser l'architecture backend, utiliser des modèles prédictifs pour anticiper la fin de l'énoncé.116  
  * *Signaux Clairs de Cession de Tour :* L'agent doit poser des questions claires pour indiquer que c'est au tour de l'utilisateur.118 Éviter de parler après avoir posé une question ou de poser plusieurs questions à la fois.118  
  * *Détection Avancée de Fin de Tour :* Utiliser des modèles ML entraînés sur des indices verbaux/non-verbaux 119, des VAD adaptatives 120, ou des modèles spécialisés comme TurnGPT ou VAP.119  
  * *Gestion des Interruptions (Barge-in) 119 :*  
    * *Canal Duplex :* Idéalement, le système doit pouvoir écouter tout en parlant.119  
    * *Classification des Chevauchements :* Utiliser des modèles pour distinguer les vraies interruptions des backchannels ou du bruit.119  
    * *Récupération Gracieuse :* Prévoir des mécanismes pour reprendre la conversation de manière fluide après une interruption (qu'elle soit justifiée ou non). Une interruption mal gérée peut nuire à l'expérience.119  
  * *Gestion des Backchannels 119 :* Reconnaître que des interjections comme "uh-huh" ou "ok" ne sont pas nécessairement des tentatives d'interruption. Le système devrait idéalement continuer sauf si une intention claire d'interrompre est détectée.119

La gestion de l'initiative et celle des tours de parole sont étroitement liées. Décider de prendre l'initiative implique souvent que l'agent garde la parole pour poser une question directrice.117 Céder l'initiative nécessite de reconnaître la tentative de l'utilisateur de prendre la parole, que ce soit après une pause ou par une interruption.119 Une stratégie d'initiative mixte efficace repose donc sur des mécanismes robustes de détection et de gestion des tours de parole. Déterminer *quand* prendre ou céder l'initiative relève de la politique de dialogue.90 *Exécuter* cette décision dépend de la mécanique des tours de parole. Si l'agent décide de poser une question (prise d'initiative), il doit clairement signaler la fin de son tour.118 S'il décide de céder la parole, il doit détecter avec précision la fin du tour de l'utilisateur ou sa tentative d'interruption.116 Une mauvaise gestion des tours 116 sapera même une stratégie d'initiative bien conçue. AutoAgent doit donc considérer conjointement la stratégie d'initiative de haut niveau et l'implémentation de bas niveau de la prise de tour.

Simuler une prise de tour fluide et naturelle représente un défi technique considérable. Cela exige une faible latence, une détection précise de la fin de parole, et une gestion sophistiquée des interruptions et des backchannels.116 Une simple VAD basée sur le silence est souvent inadéquate.119 Les difficultés incluent les problèmes de latence, la distinction entre pauses et fin de tour (TRPs), et l'identification des vraies interruptions par rapport aux backchannels ou au bruit. Les solutions passent par des modèles prédictifs, des modèles de prise de tour spécialisés (TurnGPT, VAP), des canaux duplex, et des classificateurs ML pour les types de chevauchement.116 Cela implique que la mise en œuvre d'une prise de tour naturelle pour l'Orchestrateur d'AutoAgent (surtout si une interaction vocale est envisagée à l'avenir) nécessitera un effort d'ingénierie significatif allant au-delà des frameworks de chatbot basiques. Pour le chat actuel, minimiser la latence de réponse du système 116 reste critique pour éviter la frustration de l'utilisateur et le sentiment de se "couper la parole".

Bien que les LLM puissent être sollicités pour générer un dialogue à initiative mixte 92, s'assurer que l'agent prend l'initiative de manière *appropriée* (par exemple, pour guider vers la complétion de la checklist) tout en permettant des contributions naturelles de l'utilisateur nécessite un prompt engineering soigné ou un contrôle de politique. Un contrôle trop rigide peut sembler artificiel, tandis qu'une trop grande liberté risque de faire manquer des informations requises. 92/92 montrent que les LLM peuvent remplacer le fine-tuning pour une génération *contrôlable* basée sur des intentions/stratégies. 117 souligne le besoin de flexibilité où les rôles ne sont pas prédéterminés. Le défi pour AutoAgent est d'utiliser cette contrôlabilité (via des prompts ou d'autres mécanismes de politique) pour assurer la couverture de la checklist, mais *sans* revenir à un script rigide dirigé par le système qui annulerait l'objectif de naturalité. Cela renforce la nécessité de politiques adaptatives (Section III) capables d'équilibrer les objectifs du système (checklist) avec la flexibilité conversationnelle (initiative utilisateur, flux naturel). La formalisation du prompt mentionnée dans 92/92 pourrait être une clé ici.

## **V. Conception Centrée sur l'Humain : Application des Principes de Communication et de Cognition**

Pour créer une expérience de clarification d'exigences qui soit non seulement efficace mais aussi naturelle et agréable, il est crucial d'intégrer des principes issus de l'étude de la communication humaine et de la psychologie cognitive dans la conception de l'Orchestrateur.

### **Maximes de Grice et Théorie de la Politesse dans la Conception de l'Agent**

* **Principe de Coopération de Grice** 118 **:** Le philosophe Paul Grice a postulé que les participants à une conversation opèrent sous un "Principe de Coopération", s'attendant mutuellement à ce que leurs contributions soient appropriées au but et à la direction acceptés de l'échange.118 Ce principe est pertinent pour l'IHM car les utilisateurs tendent à appliquer les mêmes attentes de coopération aux agents IA.118 L'Orchestrateur doit donc être conçu pour être perçu comme un partenaire coopératif dans la tâche de définition de la mission.  
* **Maximes Gricéennes** 118 **:** Pour respecter le Principe de Coopération, Grice a défini quatre maximes conversationnelles qui peuvent guider la conception des questions et réponses de l'agent :  
  * *Maxime de Quantité :* Fournir autant d'information que nécessaire, mais pas plus. Éviter les réponses trop laconiques ou excessivement verbeuses.118 Les interventions de l'agent doivent faire avancer la conversation vers l'objectif.118  
  * *Maxime de Qualité :* Être véridique ; ne pas affirmer ce que l'on croit faux ou pour quoi on manque de preuves.118 Les réponses de l'agent doivent être factuelles et basées sur les informations disponibles.122  
  * *Maxime de Relation (Pertinence) :* Être pertinent. Les contributions doivent avoir un lien avec le sujet en cours.118 Les réponses de l'agent doivent directement adresser l'énoncé de l'utilisateur ou l'objectif courant de la clarification.122  
  * *Maxime de Manière :* Être clair, bref et ordonné ; éviter l'obscurité et l'ambiguïté.118 Utiliser un langage simple et éviter le jargon technique inutile.118  
* **Adaptation des Maximes pour l'IA** 121 **:** Étant donné l'asymétrie de l'interaction homme-IA, des maximes supplémentaires ont été proposées :  
  * *Bienveillance :* Éviter les contenus insensibles, impolis ou nuisibles ; refuser de s'engager dans des requêtes dangereuses ou non éthiques.  
  * *Transparence :* Reconnaître les limites de ses connaissances, ses capacités opérationnelles et sa volonté (ou non) d'aborder certains sujets.  
* **Théorie de la Politesse (Brown & Levinson)** 124 **:**  
  * *Concept :* La politesse concerne la gestion de la "face" sociale des interactants : la face positive (désir d'être apprécié, approuvé) et la face négative (désir d'autonomie, de ne pas subir d'imposition). Les actes menaçant la face (Face-Threatening Acts \- FTAs), comme les requêtes, les désaccords ou les demandes de clarification, nécessitent des stratégies de politesse pour en atténuer l'impact.  
  * *Application aux Chatbots :* La politesse est pertinente dans l'interaction homme-chatbot 124, en particulier pour des tâches potentiellement sensibles (comme le support en santé mentale 126) ou fastidieuses (comme la clarification d'exigences). Les utilisateurs peuvent adopter un comportement poli envers les bots par habitude.125  
  * *Impact sur l'Expérience Utilisateur 126 :* Une politesse appropriée peut être perçue positivement (sentiment d'être pris en charge, soutenu, encouragé). Cependant, une politesse excessive ou mal employée peut avoir des effets négatifs : l'agent peut paraître trop apologétique, condescendant ou peu fiable.  
  * *Stratégies :* L'Orchestrateur devrait utiliser des stratégies de politesse (ex: utiliser des atténuateurs, des excuses pour les demandes répétitives, formuler les clarifications de manière indirecte) pour rendre les demandes d'information ou la gestion des contradictions moins abruptes, mais doit éviter une politesse artificielle ou excessive qui pourrait nuire à la confiance.

### **Minimiser la Charge Cognitive : Conception pour l'Attention et la Mémoire Humaines**

* **Charge Cognitive** 127 **:** La charge cognitive désigne l'effort mental requis pour raisonner et traiter l'information lors d'une interaction.130 Une charge cognitive élevée peut entraver la compréhension et la performance. Un objectif clé de la conception d'interface, y compris conversationnelle, est de minimiser la charge cognitive inutile imposée à l'utilisateur.130  
* **Pertinence pour le Dialogue de Clarification :** Définir des exigences complexes peut être une tâche cognitivement exigeante pour l'utilisateur. La conception de l'interaction avec l'Orchestrateur doit viser à alléger ce fardeau autant que possible.  
* **Principes de Conception** 127 **:**  
  * *Brièveté et Clarté (Maxime de Manière) :* Déjà couvert par les maximes de Grice. Éviter les questions ou réponses longues et complexes. Utiliser un langage simple.118  
  * *Découpage de l'Information (Chunking) :* Présenter l'information par petits morceaux gérables. Éviter de submerger l'utilisateur avec trop de questions ou d'options en un seul tour.118  
  * *Apprentissage Progressif / Divulgation Progressive 130 :* Introduire la complexité graduellement. Ne pas demander toutes les informations d'un coup. Guider l'utilisateur étape par étape.  
  * *Résumé (Voir Section II) :* Utiliser des résumés progressifs 66 pour rafraîchir la mémoire de l'utilisateur, confirmer la compréhension et réduire la nécessité de tout mémoriser mentalement.63  
  * *Exploiter la Mémoire Externe (Visuel) :* Utiliser explicitement l'espace visuel de l'interface de chat (le "Canvas" mentionné dans la requête initiale) comme aide-mémoire externe. Afficher visuellement l'état de la checklist et les informations recueillies réduit la charge de mémorisation pour l'utilisateur.130  
  * *Simplicité et Intuitivité 130 :* Concevoir un flux d'interaction intuitif, en capitalisant sur les compétences conversationnelles existantes de l'utilisateur ("Expertise Instantanée" 130).  
  * *Fonctions de Forçage Cognitif (Cognitive Forcing Functions \- CFFs) 127 :* Mécanismes conçus pour encourager une réflexion plus délibérée (Système 2\) chez l'utilisateur, potentiellement utiles si celui-ci donne des réponses superficielles. Cependant, ils peuvent augmenter l'effort cognitif.128 Exemples : questions posées par l'IA, demande de feedback explicite.127

### **Stratégies pour Maintenir l'Engagement et la Motivation de l'Utilisateur**

* **Le Défi :** La clarification d'exigences peut être un processus long et potentiellement fastidieux. La conception doit maintenir l'utilisateur engagé et motivé tout au long de l'interaction.  
* **Techniques :**  
  * *Naturalité et Fluidité :* Une interaction lisse et non robotique (Sections II, III, IV) est intrinsèquement plus engageante.  
  * *Démonstration de Compréhension (Écoute Active) :* Fait sentir à l'utilisateur qu'il est entendu et compris, ce qui est valorisant.47  
  * *Personnalisation :* Adapter le langage ou le style d'interaction.10 Se souvenir du contexte.116  
  * *Feedback et Indicateurs de Progrès :* Utiliser les résumés (Section II) et les mises à jour visuelles de la checklist (voir Charge Cognitive) pour montrer l'avancement.  
  * *Politesse et Cadrage Positif :* Utiliser une politesse appropriée (voir ci-dessus) et formuler les requêtes de manière positive.  
  * *Variété du Style d'Interaction :* Éviter la monotonie.118 Alterner questions directes, confirmations, résumés, et laisser l'initiative à l'utilisateur.  
  * *Efficacité :* Respecter le temps de l'utilisateur en étant concis et en faisant avancer la conversation de manière productive.1  
  * *Enthousiasme/Encouragement (avec mesure) :* Utiliser des phrases encourageantes lorsque c'est pertinent ("Parfait, nous avançons bien.").50

La conception d'une IA conversationnelle efficace ne repose pas uniquement sur la technologie (TALN, ML), mais est fondamentalement ancrée dans la compréhension et l'application des principes de la communication humaine (Maximes de Grice 118) et de l'interaction sociale (Théorie de la Politesse 124). Ignorer ces principes conduit à des expériences non naturelles et frustrantes. Les utilisateurs appliquent leurs attentes conversationnelles humaines (Principe de Coopération) à l'IA.118 L'applicabilité directe des Maximes de Grice à la conception de systèmes TALN est démontrée 123, et l'impact (positif et négatif) de la politesse dans les interactions avec les chatbots est étudié.124 Cela implique que la conception d'AutoAgent ne doit pas se concentrer uniquement sur la tâche fonctionnelle (complétion de la checklist), mais doit activement intégrer ces principes centrés sur l'humain dans le langage et le comportement de l'agent pour assurer son acceptation et son efficacité.

Les limitations cognitives des utilisateurs humains (attention, mémoire de travail 130) constituent une contrainte majeure pour la conception de dialogues, en particulier pour des tâches complexes comme la clarification d'exigences. Surcharger l'utilisateur mène à des erreurs, de la frustration et à l'abandon. La clarification d'exigences sollicite intrinsèquement les ressources cognitives (rappel de détails, prise de décision, suivi de la progression). La charge cognitive 130 doit être minimisée. Des principes comme la brièveté 118, l'apprentissage progressif 130, et l'utilisation d'aides externes (visuels, résumés 63) répondent directement à ce besoin. Par conséquent, le flux de dialogue de l'Orchestrateur d'AutoAgent *doit* être conçu avec la minimisation de la charge cognitive comme objectif principal, en utilisant des techniques comme le découpage des questions, des résumés fréquents et des aides visuelles dans l'interface de chat.

L'application de la politesse n'est pas triviale. Bien que généralement bénéfique, une politesse inappropriée ou excessive peut se retourner contre l'agent, le faisant paraître peu sincère, condescendant ou indigne de confiance.126 Le niveau et le type de politesse adéquats dépendent fortement du contexte. Des études montrent des réactions utilisateur à la fois positives (attentionné, soutenant) et négatives (condescendant, peu fiable) à la politesse des chatbots dans un contexte sensible.126 Les utilisateurs peuvent aussi être polis par habitude.125 Cela suggère la nécessité d'un calibrage minutieux. L'Orchestrateur d'AutoAgent a besoin de politesse pour gérer une tâche potentiellement longue et exigeante, mais celle-ci doit être contextuellement appropriée – peut-être plus directe lors de la confirmation de faits, plus atténuée ou apologétique lors de la signalisation de contradictions ou de la pose de questions répétitives. Une stratégie de politesse uniforme est risquée.

## **VI. Combler le Fossé : Architectures pour la Structure et la Fluidité**

Le défi central pour l'Orchestrateur d'AutoAgent est de concilier sa nécessité interne de suivre une structure rigoureuse (la checklist de mission) avec l'objectif externe d'offrir une conversation fluide et adaptative. Cela nécessite des choix architecturaux et des patrons de conception spécifiques.

### **Patrons de Conception pour une Collecte d'Informations Flexible**

* **Le Problème Fondamental :** Comment permettre à l'agent de suivre sa checklist interne pour assurer la complétude et la fiabilité, tout en donnant à l'utilisateur l'impression d'une conversation naturelle et non d'un interrogatoire scripté?  
* **Remplissage Flexible de Slots (Flexible Slot Filling) :**  
  * *Concept :* Dépasser le modèle rigide où le système demande une information (un slot) à la fois. Permettre aux utilisateurs de fournir plusieurs éléments d'information dans un seul énoncé, potentiellement dans le désordre ou de manière implicite.12  
  * *Techniques Facilitatrices :* Repose fortement sur une NLU avancée (Section II) pour extraire plusieurs slots, gérer les mentions implicites 16, résoudre les coréférences 36, et potentiellement induire de nouveaux slots pertinents.26 Le gestionnaire de dialogue (Section III) doit suivre les slots déjà remplis et adapter sa stratégie de questionnement en conséquence.  
  * *Exemple :* Si l'utilisateur dit : "Je veux un outil pour analyser les retours clients des enquêtes et des réseaux sociaux, en me concentrant sur le sentiment, d'ici le prochain trimestre." Le système devrait extraire Tâche=Analyser Retours Clients, SourceDonnées=Enquêtes, SourceDonnées=Réseaux Sociaux, TypeAnalyse=Sentiment, Échéance=Prochain Trimestre, même si ces informations n'ont pas été demandées explicitement dans cet ordre.  
* **Structures de Buts/Tâches Hiérarchiques** 134 **:**  
  * *Concept :* Reconnaître que les missions complexes peuvent avoir des structures hiérarchiques (objectifs principaux décomposés en sous-objectifs ou étapes). Le dialogue peut s'adapter en fonction de cette structure.  
  * *Patrons Architecturaux :* Le patron "Agent Hiérarchique" 136 où des agents de niveau supérieur délèguent des tâches. Des systèmes comme HierTOD 134 sont conçus pour des tâches d'entreprise multi-niveaux, contrastant avec les flux de travail simples à un seul niveau.134 HierTOD utilise un référentiel de buts et détermine s'il faut utiliser le remplissage de slots ou un guidage pas-à-pas.134  
  * *Application Potentielle :* La clarification de mission d'AutoAgent pourrait être modélisée hiérarchiquement (ex: Définir l'objectif global \-\> Définir le contexte \-\> Définir les contraintes \-\> Définir les livrables). Le gestionnaire de dialogue pourrait naviguer cette hiérarchie de manière flexible.  
* **Gestion de Dialogue Basée sur des Plans** 87 **:** Mentionner brièvement les modèles basés sur des plans où le système infère le plan sous-jacent de l'utilisateur (les étapes nécessaires pour définir la mission) et collabore pour l'atteindre. Cela permet une interaction plus dynamique que le simple remplissage de slots séquentiel.

### **Intégration des Checklists Internes avec des Flux de Dialogue Adaptatifs**

* **Considérations Architecturales :** Comment concevoir le système pour suivre l'avancement de la checklist tout en permettant une liberté conversationnelle?  
  * *Représentation de l'État du Dialogue :* Le DST (Section III) doit représenter non seulement les valeurs des slots extraites mais aussi le statut des éléments de la checklist (ex: en attente, rempli, confirmé).  
  * *Stratégie de Politique :* La politique de dialogue adaptative (Section III) doit équilibrer plusieurs objectifs : collecter les informations manquantes de la checklist, confirmer les informations incertaines, répondre aux questions de l'utilisateur, et maintenir le flux et l'engagement conversationnel. Les politiques RL pourraient potentiellement apprendre cet équilibre si la fonction de récompense intègre la complétion de la checklist.97  
  * *Patron Orchestrateur-Travailleur (Orchestrator-Worker) 136 :* L'agent Orchestrateur peut être vu comme gérant des sous-agel’nts ou des modules internes responsables de parties spécifiques de la checklist ou de fonctions du dialogue. La communication basée sur des événements 136 pourrait gérer les interactions.  
  * *Patron Tableau Noir (Blackboard) 136 :* Envisager une base de connaissances partagée (le "tableau noir") représentant l'état actuel de la définition de la mission (statut de la checklist, informations recueillies). Le gestionnaire de dialogue et les composants NLU interagissent avec ce tableau noir. Cela permet des mises à jour asynchrones et une collaboration entre les composants.  
  * *Approches Hybrides 38 :* Réitérer l'idée de systèmes hybrides combinant des éléments structurés (règles, FSM pour les vérifications critiques) avec des composants flexibles (ML/RL/LLM pour la compréhension et la génération).83 Rasa CALM 38 en est un exemple : LLM pour la compréhension, "Flows" prédéfinis (logique structurée) pour l'exécution. AutoAgent pourrait utiliser des flux pour garantir la couverture de la checklist mais permettre une flexibilité guidée par LLM dans la manière dont les questions sont posées ou l'input utilisateur est traité.

La checklist interne ne doit pas être vue comme une simple liste statique à remplir séquentiellement, mais plutôt comme la définition de l'*état objectif* de la conversation. La gestion adaptative du dialogue (Section III) et le remplissage flexible de slots 23 permettent au système de naviguer vers cet état objectif de manière opportuniste, en remplissant les slots au fur et à mesure que l'utilisateur fournit l'information, plutôt que de forcer une séquence rigide. Les approches traditionnelles de remplissage de slots impliquent souvent un formulaire fixe.87 Cependant, les utilisateurs fournissent l'information de manière non linéaire (ce qui est implicite dans le besoin de dialogue adaptatif 89). Le remplissage flexible de slots 23 et un DST avancé 7 permettent de suivre la progression par rapport à la checklist quel que soit l'ordre de l'input. Les structures hiérarchiques 134 permettent d'aborder des sous-objectifs. Cela recadre le problème : la checklist définit le *quoi*, tandis que la gestion adaptative du dialogue définit le *comment* (le chemin flexible). AutoAgent devrait traiter la checklist comme un état cible au sein d'un cadre de dialogue adaptatif, et non comme un script rigide.

Les patrons de conception architecturaux comme Orchestrateur-Travailleur, Hiérarchique, et Tableau Noir 136 offrent des moyens éprouvés de structurer des systèmes multi-composants (comme un agent de dialogue interagissant avec des modules NLU, DST, Politique, NLG) pour gérer la complexité, permettre un traitement asynchrone, et faciliter l'intégration d'éléments structurés (suivi de checklist) et fluides (interaction conversationnelle). Un système de dialogue monolithique est difficile à construire et à maintenir. Les pipelines modulaires classiques ont leurs propres problèmes.17 Le patron Tableau Noir 136 permet à différents composants (NLU mettant à jour les slots, Politique décidant de la prochaine question en fonction des slots non remplis) d'interagir via une représentation d'état partagée (la définition de la mission). Les patrons hiérarchiques conviennent aux tâches complexes.134 Les approches basées sur les événements 136 améliorent la réactivité. Choisir un patron architectural approprié aide AutoAgent à gérer l'interaction entre son besoin de suivi d'état interne (checklist) et sa logique d'interface conversationnelle.

Les systèmes purement basés sur des règles sont trop rigides 84, tandis que les systèmes purement pilotés par LLM peuvent manquer de fiabilité pour la collecte de données critiques.38 Les architectures hybrides, combinant explicitement un contrôle structuré (flux, règles) avec une IA flexible (LLM pour NLU/NLG, politiques adaptatives), représentent une approche pragmatique pour atteindre à la fois la fiabilité (complétion de la checklist) et la naturalité (conversation fluide).38 La tension fondamentale est entre structure et fluidité. Les limites des systèmes purs FSM/règles sont discutées.83 Rasa CALM 38 propose explicitement un hybride : LLM pour la compréhension, Flux structurés pour la logique d'exécution. Ce patron répond directement au défi d'AutoAgent. L'implication est qu'AutoAgent devrait sérieusement envisager une architecture hybride où, par exemple, une politique adaptative guide la conversation, mais des vérifications basées sur des règles garantissent que tous les éléments obligatoires de la checklist sont finalement demandés et confirmés, ou où des LLM reformulent les prompts système générés par un module de politique plus structuré.

## **VII. Apprendre de la Pratique : Études de Cas et Bonnes Pratiques**

L'analyse d'exemples concrets et la synthèse des meilleures pratiques peuvent fournir des orientations précieuses pour la conception de l'Orchestrateur d'AutoAgent.

### **Analyse d'Agents Conversationnels Réussis pour la Clarification/Élicitation**

Identifier des agents conversationnels reconnus pour leur efficacité dans des tâches similaires de collecte d'informations complexes ou de clarification d'exigences permet de tirer des leçons applicables.

* **IA pour l'Analyse des Exigences (Études de Cas)** 137 **:** Bien que toutes ces études ne portent pas spécifiquement sur des agents *conversationnels* d'élicitation, elles montrent l'utilisation de l'IA pour des tâches connexes : extraction d'exigences à partir de transcriptions ou de notes 138, identification d'ambiguïtés 140, génération de user stories ou de critères d'acceptation 139, et amélioration de la qualité et de la vitesse du processus d'analyse.137 L'assistant Haiven de Thoughtworks, utilisant des prompts et du contexte, est un exemple notable.137 Des outils comme Copilot4DevOps 139 ou ClickUp AI 141 automatisent certaines parties du processus.  
* **Techniques d'Élicitation Conversationnelle** 147 **:** Les techniques utilisées par les analystes humains lors de l'élicitation sont souvent adaptables à un agent IA. Celles-ci incluent l'observation 148, la revue de diagrammes/prototypes 148, les entretiens (structurés ou non) 150, le brainstorming 150, le laddering (poser des "pourquoi?" successifs pour remonter aux motivations profondes) 152, et même des techniques plus orientées ou persuasives (ex: "Can you top this?", critique constructive, fausses déclarations délibérées pour obtenir une correction).147 LadderBot est un exemple de CA utilisant le laddering pour l'élicitation.155 La méthode Two-phase Requirement Elicitation 151 planifie une séquence d'exigences potentielles et détecte en temps réel les besoins de l'utilisateur.  
* **Exemples de Chatbots Spécifiques** 2 **:** Bien que souvent conçus pour des tâches plus simples, certains chatbots illustrent des principes pertinents. Turing AI de DevRev génère une base de connaissances à partir des conversations.157 L'assistant virtuel de Home Depot utilise le TALN pour comprendre les requêtes.158 Les chatbots pour la gestion des connaissances ou le triage de tickets posent des questions de clarification pour obtenir plus d'informations.156 La conscience contextuelle est également mise en avant.2  
* **Systèmes de Dialogue Adaptatifs (Études de Cas)** 159 **:** Des systèmes de recherche comme CEDERIC (contrôle de drone UAV, raisonnement à base de cas pour l'adaptation) 160, DAST (adaptation de domaine avec architecture étudiant-professeur) 161, ou des interfaces adaptatives basées sur des agents 162 montrent la faisabilité de systèmes qui s'ajustent au contexte ou à l'utilisateur.  
* **Leçons Apprises :**  
  * L'importance cruciale de fournir un **contexte** pertinent à l'IA pour qu'elle soit efficace.137  
  * La nécessité d'une **courbe d'apprentissage** pour les utilisateurs interagissant avec des IA non déterministes.137  
  * L'importance de **prompts clairs et précis** pour guider l'IA.138  
  * La nécessité de combiner les capacités de l'IA avec une **supervision et une validation humaines**.144  
  * Le potentiel d'amélioration de la **qualité et de la vitesse** des processus d'analyse/élicitation grâce à l'IA.137  
  * L'applicabilité des **techniques d'élicitation structurées** (comme le laddering 152) dans un contexte conversationnel IA.

### **Synthèse des Bonnes Pratiques pour les Dialogues Adaptatifs de Collecte d'Exigences**

En se basant sur les principes et les exemples étudiés, voici une synthèse des bonnes pratiques :

* **Phase de Conception** 1 **:**  
  * *Définir Objectif et Périmètre Clairs :* Préciser ce que l'Orchestrateur doit accomplir (checklist).1 Définir une stratégie claire dès le départ.164  
  * *Conception Centrée Utilisateur :* Comprendre les buts et le contexte des utilisateurs.1 Concevoir des flux intuitifs.2  
  * *Définir une Persona :* Créer une personnalité d'agent cohérente et appropriée (coopérative, polie, claire).118  
* **Conception de l'Interaction** 1 **:**  
  * *Respecter le Principe de Coopération :* Concevoir l'agent pour qu'il soit coopératif, véridique, pertinent et clair (Maximes de Grice).1  
  * *Être Conscient du Contexte :* Maintenir et exploiter le contexte tout au long du dialogue.1  
  * *Clarté et Brièveté :* Utiliser un langage simple, éviter le jargon, être concis.1 Fournir des appels à l'action clairs (poser des questions).118  
  * *Gérer les Tours de Parole :* Assurer des transitions fluides, minimiser la latence.1  
  * *Gérer les Erreurs :* Prévoir une gestion gracieuse des erreurs et des stratégies de clarification.2 Gérer l'ambiguïté.122  
  * *Utiliser la Politesse à Bon Escient :* Appliquer la politesse de manière appropriée, surtout pour les interactions sensibles ou les corrections.1  
  * *Minimiser la Charge Cognitive :* Découper l'information, utiliser des résumés, exploiter les aides visuelles.130  
  * *Être Flexible :* Permettre l'initiative de l'utilisateur et les écarts par rapport au "script".83  
  * *Intégrer des Mécanismes de Feedback :* Permettre aux utilisateurs de donner leur avis pour l'amélioration continue.44  
* **Implémentation Technique :**  
  * *NLU/DST Robustes :* Investir dans une compréhension et un suivi d'état précis (Sections II, III).  
  * *Gestion de Dialogue Adaptative :* Employer des politiques flexibles (Section III).  
  * *Architectures Hybrides :* Envisager d'équilibrer structure et flexibilité (Section VI).  
* **Test et Itération** 44 **:** Tester continuellement avec les utilisateurs, recueillir du feedback, et itérer sur la conception et les modèles. Surveiller la performance après le déploiement.163

De nombreuses techniques d'élicitation établies entre humains 148 peuvent être adaptées et potentiellement automatisées ou semi-automatisées par des agents conversationnels. Cela offre des moyens structurés de sonder les besoins profonds au-delà des demandes de surface. Des études mentionnent explicitement l'utilisation du laddering par un chatbot (LadderBot).152 Cela suggère que l'Orchestrateur d'AutoAgent n'est pas limité à une conversation non structurée ; il pourrait intégrer des schémas conversationnels basés sur des méthodes d'élicitation éprouvées pour guider plus efficacement l'utilisateur vers la révélation des objectifs, contraintes ou hypothèses sous-jacents liés à la mission.

Les études de cas 137 montrent de manière constante que l'IA est utilisée pour *assister* les analystes humains (BA, QA) en automatisant la transcription, en résumant les notes, en générant des ébauches d'exigences ou de cas de test, et en identifiant les lacunes. La supervision humaine, la fourniture de contexte et la validation restent cruciales. L'étude de Thoughtworks 137 souligne la courbe d'apprentissage de l'utilisateur et le besoin de contexte. D'autres insistent sur la combinaison de l'IA avec la supervision humaine et la revue itérative 144, et notent que la collecte et l'analyse restent principalement humaines.145 Cela implique que l'Orchestrateur d'AutoAgent devrait être conçu comme un outil pour *aider* l'utilisateur à définir la mission, et non pour remplacer sa réflexion. Il doit faciliter le processus, structurer l'information, et peut-être suggérer des pistes, mais la définition finale et la validation dépendent de l'utilisateur humain.

Le succès de l'IA dans l'analyse ou la collecte d'exigences dépend fortement de la fourniture d'un contexte suffisant et précis concernant le domaine, les systèmes existants et les objectifs du projet.137 Une IA générique sans contexte est beaucoup moins efficace. L'étude de Thoughtworks 137 indique explicitement que l'équipe a investi du temps pour créer un contexte réutilisable pour son assistant IA. D'autres soulignent l'importance de fournir des détails contextuels dans les prompts.138 Cela renforce la nécessité pour l'Orchestrateur d'AutoAgent d'avoir accès à des informations contextuelles pertinentes (peut-être sur les missions passées, les normes organisationnelles, les outils/agents disponibles) pour mener un dialogue de clarification efficace. Le mécanisme de fourniture de ce contexte (par exemple, input initial de l'utilisateur, récupération depuis une base de connaissances) est une considération de conception clé.

## **VIII. Recommandations Actionnables pour l'Orchestrateur d'AutoAgent V1**

Basées sur l'exploration approfondie des techniques et principes décrits précédemment, voici des recommandations spécifiques et actionnables pour la conception de la logique conversationnelle de l'agent Orchestrateur d'AutoAgent V1, visant à rendre l'interaction de clarification aussi naturelle, adaptative et efficace que possible.

### **Techniques TALN et Modèles de Gestion de Dialogue Recommandés**

* **Compréhension du Langage Naturel (NLU) :**  
  * Utiliser des techniques robustes pour la reconnaissance d'intention, l'extraction d'entités et le remplissage de slots. Envisager des modèles qui traitent conjointement l'intention et les slots pour bénéficier de leur corrélation.12  
  * Intégrer impérativement des mécanismes de **résolution de coréférence** pour gérer les pronoms et autres références contextuelles.36  
  * Développer des capacités de gestion de l'**information implicite**, au-delà de l'extraction littérale.23  
  * Adopter une approche de **remplissage de slots flexible**, permettant à l'utilisateur de fournir des informations dans le désordre ou de manière groupée.  
  * Explorer l'**induction de slots** 26 si le périmètre des missions est susceptible d'évoluer, afin de ne pas être limité par une checklist prédéfinie trop rigide.  
  * Compte tenu du besoin de fiabilité pour la collecte d'exigences, privilégier des modèles NLU **affinés (fine-tuned)** sur des données spécifiques à la tâche plutôt que de se fier uniquement à des LLM zero-shot pour l'extraction critique. Les LLM peuvent cependant être utilisés pour une compréhension initiale plus large, la paraphrase ou la génération de réponses (approche hybride).  
* **Suivi de l'État du Dialogue (DST) :**  
  * Implémenter un modèle DST moderne capable de gérer le contexte multi-tours et la variation linguistique (ex: génération texte-à-texte 7 ou modèles neuronaux dédiés).  
  * La représentation de l'état doit inclure non seulement les paires slot-valeur recueillies mais aussi explicitement le **statut de chaque élément de la checklist interne** (ex: objectif\_principal: en\_attente, contrainte\_budget: rempli, livrable\_format: confirmé).  
* **Gestion de Dialogue Adaptative :**  
  * Éviter les FSM purement rigides. Recommander une **approche hybride** 38 ou une **politique RL soigneusement conçue**.93  
  * *Option Hybride :* Utiliser des flux structurés (similaires aux "Flows" de Rasa 38) ou des règles pour garantir que les grandes catégories de la checklist (Objectifs, Contexte, Contraintes, Livrables) sont abordées et confirmées. Au sein de chaque catégorie, utiliser une politique plus flexible (basée ML ou guidée par LLM via prompting 92) pour poser des questions de manière adaptative en fonction des informations déjà fournies et des slots remplis. Utiliser les capacités de génération des LLM (NLG) pour reformuler les questions et réponses de manière naturelle.  
  * *Option RL :* Si le RL est choisi, concentrer l'effort sur la **conception de la fonction de récompense**. Utiliser des récompenses pas-à-pas 97 intégrant à la fois la progression dans la checklist (récompense de compréhension/DST) et des métriques de qualité conversationnelle (pertinence, brièveté, politesse, engagement). Commencer par du RL hors ligne 97 avec une politique pré-entraînée.98 Envisager l'IRL/GDPL 100 si des données de dialogue humain pertinentes sont disponibles.

### **Stratégies Spécifiques pour l'Écoute Active, l'Initiative et la Gestion de la Charge Cognitive**

* **Écoute Active Simulée :**  
  * Implémenter la **reformulation contextuelle** (orientée tâche 53) et la **paraphrase variée** 11 pour confirmer la compréhension sans robotisme.  
  * Utiliser des **questions de clarification ciblées** 52 lorsque l'ambiguïté est détectée (faible confiance NLU/DST).  
  * Employer le **résumé progressif** 66 à des points de transition logiques (ex: après la discussion des objectifs, avant d'aborder les contraintes) pour valider la compréhension et gérer la charge cognitive.  
  * Utiliser des **accusés de réception subtils** et contextuels ("Compris", "Noté") pour signaler l'écoute.50  
* **Gestion de l'Initiative :**  
  * Adopter une stratégie d'**initiative mixte**.117 L'agent prend l'initiative pour guider à travers les sections de la checklist et poser des questions de clarification nécessaires.  
  * Permettre l'**initiative de l'utilisateur** pour qu'il puisse élaborer, poser des questions, ou fournir des informations spontanément.  
  * Adapter le niveau de guidage en fonction de l'interaction : si l'utilisateur est proactif et détaillé, réduire les questions directes de l'agent.  
* **Gestion de la Charge Cognitive :**  
  * **Structurer** la clarification en phases logiques (Objectifs, Contexte, Contraintes, Livrables).  
  * Poser des **questions claires et concises**.118 Éviter de poser plusieurs questions non liées en un seul tour.118  
  * Utiliser l'**interface de chat (Canvas)** comme **mémoire externe** : afficher visuellement le statut de la checklist et les informations clés recueillies au fur et à mesure.130  
  * Utiliser fréquemment les **résumés progressifs** pour rafraîchir la mémoire et confirmer.63

### **Considérations Architecturales pour Intégrer Structure et Fluidité**

* **Architecture Hybride :** Concevoir explicitement pour l'hybridité.38 Séparer la compréhension (NLU) de la politique/exécution. S'appuyer sur un DST robuste pour suivre l'état de la checklist.  
* **Conception Modulaire :** Envisager des patrons comme le **Tableau Noir (Blackboard)**.136 La NLU met à jour un état partagé (la définition de la mission en cours), et le module de Politique lit cet état pour décider de la prochaine action (ex: demander le prochain élément non rempli, clarifier, résumer).  
* **Intégration de la Checklist :** La politique de dialogue doit explicitement interroger le DST sur le statut des éléments de la checklist pour guider ses actions vers la complétion. Des règles ou des états spécifiques de la politique peuvent imposer la couverture des éléments obligatoires avant de conclure la phase de clarification.  
* **Fourniture de Contexte :** Prévoir un mécanisme permettant à l'Orchestrateur d'accéder au contexte pertinent (profil utilisateur, missions antérieures, capacités du système AutoAgent) pour informer la compréhension et la personnalisation de l'interaction.

### **Approches d'Évaluation**

* **Évaluation des Composants :** Mesurer la performance de la NLU (précision/F1 pour intention/slots), du DST (précision conjointe des buts, précision des slots 36), et de la NLG (métriques automatiques comme BLEU/ROUGE, mais surtout évaluation humaine 107).  
* **Évaluation de Bout en Bout :** Utiliser des métriques objectives comme le Taux de Succès de la Tâche (l'agent a-t-il recueilli toutes les informations nécessaires correctement?), la Longueur/Efficacité du Dialogue.100  
* **Évaluation Humaine :** Essentielle pour les qualités subjectives. Évaluer la Naturalité, la Fluidité, la Coopérativité (respect des maximes de Grice), la Politesse, l'Engagement, l'Intelligence Perçue, la Satisfaction Utilisateur.107 Utiliser des échelles de Likert, des jugements comparatifs (tests A/B de différentes stratégies).  
* **Analyse Qualitative :** Examiner les transcriptions de dialogues pour identifier les points d'échec fréquents, les interactions maladroites, ou les moments où la charge cognitive semble élevée.

## **IX. Conclusion**

### **Synthèse des Constatations Clés**

La conception d'un agent conversationnel comme l'Orchestrateur d'AutoAgent, capable de mener une clarification d'exigences complexe de manière à la fois structurée et fluide, nécessite une approche multidimensionnelle. L'exploration des recherches en IHM, CxD, TALN et psychologie cognitive a mis en évidence plusieurs points cruciaux :

1. **La synergie NLU/DST et Écoute Active :** Une compréhension profonde et précise de l'input utilisateur (incluant les informations implicites et les coréférences) est la base indispensable pour pouvoir simuler une écoute active naturelle via des reformulations contextuelles, des clarifications ciblées et des résumés progressifs.  
2. **L'Adaptabilité au Cœur de la Gestion de Dialogue :** Les approches rigides (FSM, règles strictes) sont insuffisantes. Des modèles de gestion de dialogue adaptatifs, s'appuyant sur un DST robuste et potentiellement sur des techniques comme l'apprentissage par renforcement (avec une conception soignée de la récompense) ou le prompting de LLM, sont nécessaires pour naviguer dynamiquement dans la collecte d'informations.  
3. **L'Importance des Principes Humains :** Le respect des principes de la communication humaine (Coopération de Grice, Politesse) et la prise en compte des contraintes cognitives (charge cognitive, attention, mémoire) sont fondamentaux pour créer une expérience utilisateur engageante, efficace et non frustrante.  
4. **La Pertinence des Architectures Hybrides :** Pour concilier le besoin de structure interne (checklist) et de fluidité externe (conversation naturelle), les architectures hybrides, combinant des éléments de contrôle structuré avec la flexibilité des approches basées sur l'IA (ML, RL, LLM), apparaissent comme la solution la plus pragmatique et la plus prometteuse.

### **Perspectives pour des Dialogues de Clarification Efficaces et Naturels**

Réaliser des dialogues de clarification d'exigences qui soient perçus comme véritablement naturels et efficaces par les utilisateurs reste un défi de recherche et d'ingénierie. Cela demande une conception itérative, l'intégration de technologies robustes et une compréhension fine des mécanismes de l'interaction humaine.

Néanmoins, les techniques et principes explorés dans ce rapport offrent une base solide pour la conception de l'Orchestrateur d'AutoAgent V1. En adoptant une approche centrée sur l'utilisateur, en investissant dans des capacités NLU/DST avancées, en choisissant une architecture de dialogue adaptative et hybride, et en intégrant consciemment les principes de communication et de cognition, il est possible de créer un agent qui non seulement collecte les informations requises de manière fiable, mais le fait d'une manière qui minimise la friction, maximise l'engagement et rationalise significativement le processus de définition de mission au sein d'AutoAgent. Le succès résidera dans la capacité à trouver le juste équilibre entre la rigueur nécessaire à la machine et la fluidité attendue par l'humain.

## **X. Références**

(Liste exhaustive des sources citées 3 à 155 et 75 à 137, formatée de manière cohérente \- omise ici pour la brièveté mais serait incluse dans le rapport final).

#### **Works cited**

1. Principles of Conversational Design | Marvel Blog, accessed April 30, 2025, [https://marvelapp.com/blog/principles-of-conversational-design/](https://marvelapp.com/blog/principles-of-conversational-design/)  
2. Top Chatbot UX Tips and Best Practices for 2024 \- Netguru, accessed April 30, 2025, [https://www.netguru.com/blog/chatbot-ux-tips](https://www.netguru.com/blog/chatbot-ux-tips)  
3. Call for Main Conference Papers \- EMNLP 2025, accessed April 30, 2025, [https://2025.emnlp.org/calls/main-conference-papers/](https://2025.emnlp.org/calls/main-conference-papers/)  
4. EMNLP 2024: Call for Papers | ACL Member Portal, accessed April 30, 2025, [https://www.aclweb.org/portal/content/emnlp-2024-call-papers](https://www.aclweb.org/portal/content/emnlp-2024-call-papers)  
5. Call for Main Conference Papers \- EMNLP 2023, accessed April 30, 2025, [https://2023.emnlp.org/calls/main\_conference\_papers/](https://2023.emnlp.org/calls/main_conference_papers/)  
6. MACHINE LEARNING FOR DIALOG STATE TRACKING: A REVIEW Matthew Henderson Google, accessed April 30, 2025, [https://research.google.com/pubs/archive/44018.pdf](https://research.google.com/pubs/archive/44018.pdf)  
7. “Do you follow me?”: A Survey of Recent Approaches in Dialogue State Tracking, accessed April 30, 2025, [https://www.researchgate.net/publication/375950682\_Do\_you\_follow\_me\_A\_Survey\_of\_Recent\_Approaches\_in\_Dialogue\_State\_Tracking](https://www.researchgate.net/publication/375950682_Do_you_follow_me_A_Survey_of_Recent_Approaches_in_Dialogue_State_Tracking)  
8. Conversational Agents and Natural Language Processing: Bridging Human Communication and AI \- SmythOS, accessed April 30, 2025, [https://smythos.com/ai-agents/conversational-agents/conversational-agents-and-natural-language-processing/](https://smythos.com/ai-agents/conversational-agents/conversational-agents-and-natural-language-processing/)  
9. Natural Language Processing Unit 10 – Dialogue Systems and Chatbots \- Fiveable, accessed April 30, 2025, [https://library.fiveable.me/natural-language-processing/unit-10](https://library.fiveable.me/natural-language-processing/unit-10)  
10. Understanding Conversational Agents and AI Dialogue Systems \- SmythOS, accessed April 30, 2025, [https://smythos.com/ai-agents/conversational-agents/conversational-agents-and-ai-dialogue-systems/](https://smythos.com/ai-agents/conversational-agents/conversational-agents-and-ai-dialogue-systems/)  
11. Paraphrasing & Dialog Systems \- Meta-Guide.com, accessed April 30, 2025, [https://meta-guide.com/dialog-systems/paraphrasing-dialog-systems](https://meta-guide.com/dialog-systems/paraphrasing-dialog-systems)  
12. A survey of joint intent detection and slot-filling models in natural language understanding \- arXiv, accessed April 30, 2025, [https://arxiv.org/pdf/2101.08091](https://arxiv.org/pdf/2101.08091)  
13. Multitask learning for multilingual intent detection and slot filling in dialogue systems \- SenticNet, accessed April 30, 2025, [https://sentic.net/multilingual-intent-detection.pdf](https://sentic.net/multilingual-intent-detection.pdf)  
14. A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding | Request PDF \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/361878840\_A\_survey\_of\_joint\_intent\_detection\_and\_slot\_filling\_models\_in\_natural\_language\_understanding](https://www.researchgate.net/publication/361878840_A_survey_of_joint_intent_detection_and_slot_filling_models_in_natural_language_understanding)  
15. Enriched Pre-trained Transformers for Joint Slot Filling and Intent Detection \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2023.ranlp-1.54.pdf](https://aclanthology.org/2023.ranlp-1.54.pdf)  
16. arXiv:2402.12234v1 \[cs.CL\] 19 Feb 2024, accessed April 30, 2025, [https://arxiv.org/pdf/2402.12234](https://arxiv.org/pdf/2402.12234)  
17. End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2023.emnlp-main.363.pdf](https://aclanthology.org/2023.emnlp-main.363.pdf)  
18. The importance of conversation design in conversational AI for business | Cognizant, accessed April 30, 2025, [https://www.cognizant.com/en\_us/services/documents/the-importance-of-conversation-design-in-conversational-ai-for-business.pdf](https://www.cognizant.com/en_us/services/documents/the-importance-of-conversation-design-in-conversational-ai-for-business.pdf)  
19. 8\. Question Answering, Text Retrieval, Information Extraction, & Argumentation Mining, accessed April 30, 2025, [https://wisconsin.pressbooks.pub/naturallanguage/chapter/information-retrieval/](https://wisconsin.pressbooks.pub/naturallanguage/chapter/information-retrieval/)  
20. Slot Filling \- Papers With Code, accessed April 30, 2025, [https://paperswithcode.com/task/slot-filling](https://paperswithcode.com/task/slot-filling)  
21. Crossing the Conversational Chasm: A Primer on Natural Language Processing for Multilingual Task-Oriented Dialogue Systems \- Journal of Artificial Intelligence Research, accessed April 30, 2025, [https://www.jair.org/index.php/jair/article/download/13083/26828/31272](https://www.jair.org/index.php/jair/article/download/13083/26828/31272)  
22. An Improved Deep Reinforcement Learning for Task-oriented Dialogue System, accessed April 30, 2025, [https://www.researchgate.net/publication/365433282\_An\_Improved\_Deep\_Reinforcement\_Learning\_for\_Task-oriented\_Dialogue\_System](https://www.researchgate.net/publication/365433282_An_Improved_Deep_Reinforcement_Learning_for_Task-oriented_Dialogue_System)  
23. Zero-shot Slot Filling in the Age of LLMs for Dialogue Systems \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2411.18980v1](https://arxiv.org/html/2411.18980v1)  
24. Zero-shot Slot Filling in the Age of LLMs for Dialogue Systems \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2025.coling-industry.59.pdf](https://aclanthology.org/2025.coling-industry.59.pdf)  
25. arXiv:2411.18980v1 \[cs.CL\] 28 Nov 2024, accessed April 30, 2025, [https://arxiv.org/pdf/2411.18980](https://arxiv.org/pdf/2411.18980)  
26. Transforming Slot Schema Induction with Generative Dialogue State Inference \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2024.sigdial-1.27.pdf](https://aclanthology.org/2024.sigdial-1.27.pdf)  
27. \[2411.18980\] Zero-shot Slot Filling in the Age of LLMs for Dialogue Systems \- arXiv, accessed April 30, 2025, [https://arxiv.org/abs/2411.18980](https://arxiv.org/abs/2411.18980)  
28. Cognition-oriented Conversational AI \- Emory NLP, accessed April 30, 2025, [https://www.emorynlp.org/projects/cognition-oriented-conversational-ai](https://www.emorynlp.org/projects/cognition-oriented-conversational-ai)  
29. \[PDF\] Automatic Intent-Slot Induction for Dialogue Systems | Semantic Scholar, accessed April 30, 2025, [https://www.semanticscholar.org/paper/276c0dc230883a2db07c4849e0b74cc21be310b2](https://www.semanticscholar.org/paper/276c0dc230883a2db07c4849e0b74cc21be310b2)  
30. UNSUPERVISED INDUCTION AND FILLING OF SEMANTIC SLOTS FOR SPOKEN DIALOGUE SYSTEMS USING FRAME-SEMANTIC PARSING Yun-Nung Chen, Wil \- Microsoft, accessed April 30, 2025, [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/SlotFilling\_cemera-ready-1.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/SlotFilling_cemera-ready-1.pdf)  
31. New Alexa Research on Task-Oriented Dialogue Systems \- Amazon Science, accessed April 30, 2025, [https://www.amazon.science/blog/new-alexa-research-on-task-oriented-dialogue-systems](https://www.amazon.science/blog/new-alexa-research-on-task-oriented-dialogue-systems)  
32. Conversational AI over Military Scenarios Using Intent Detection and Response Generation, accessed April 30, 2025, [https://www.researchgate.net/publication/358912309\_Conversational\_AI\_over\_Military\_Scenarios\_Using\_Intent\_Detection\_and\_Response\_Generation](https://www.researchgate.net/publication/358912309_Conversational_AI_over_Military_Scenarios_Using_Intent_Detection_and_Response_Generation)  
33. \[2103.08886\] Automatic Intent-Slot Induction for Dialogue Systems \- arXiv, accessed April 30, 2025, [https://arxiv.org/abs/2103.08886](https://arxiv.org/abs/2103.08886)  
34. Proactive Conversational Agents \- Lizi Liao, accessed April 30, 2025, [https://liziliao.github.io/papers/WSDM2023\_Tutorial.pdf](https://liziliao.github.io/papers/WSDM2023_Tutorial.pdf)  
35. Neural Approaches to Conversational AI, accessed April 30, 2025, [https://innovate.ieee.org/wp-content/uploads/2020/03/FnT-Neural-Approaches-to-AI.pdf](https://innovate.ieee.org/wp-content/uploads/2020/03/FnT-Neural-Approaches-to-AI.pdf)  
36. Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking \- ISCA Archive, accessed April 30, 2025, [https://www.isca-archive.org/interspeech\_2021/han21\_interspeech.pdf](https://www.isca-archive.org/interspeech_2021/han21_interspeech.pdf)  
37. Conversational AI The Definitive Guide \- Gupshup, accessed April 30, 2025, [https://www.gupshup.io/developer/resources/pdf/ebooks/Conversational\_AI\_The\_Definitive\_Guide.pdf?x53179](https://www.gupshup.io/developer/resources/pdf/ebooks/Conversational_AI_The_Definitive_Guide.pdf?x53179)  
38. Conversational AI with Language Models | Rasa Documentation, accessed April 30, 2025, [https://rasa.com/docs/learn/concepts/calm/](https://rasa.com/docs/learn/concepts/calm/)  
39. \[2502.06105\] Comprehensive Framework for Evaluating Conversational AI Chatbots \- arXiv, accessed April 30, 2025, [https://arxiv.org/abs/2502.06105](https://arxiv.org/abs/2502.06105)  
40. Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2402.13043v1](https://arxiv.org/html/2402.13043v1)  
41. Semantic and pragmatic precision in conversational AI systems \- PMC \- PubMed Central, accessed April 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10101227/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10101227/)  
42. iwangjian/Paper-Reading-ConvAI: Paper reading list in conversational AI. \- GitHub, accessed April 30, 2025, [https://github.com/iwangjian/Paper-Reading-ConvAI](https://github.com/iwangjian/Paper-Reading-ConvAI)  
43. Redefining Conversational AI with Large Language Models \- Towards Data Science, accessed April 30, 2025, [https://towardsdatascience.com/redefining-conversational-ai-with-large-language-models-1ded152c3398/](https://towardsdatascience.com/redefining-conversational-ai-with-large-language-models-1ded152c3398/)  
44. Error Correction and Adaptation in Conversational AI: A Review of Techniques and Applications in Chatbots \- MDPI, accessed April 30, 2025, [https://www.mdpi.com/2673-2688/5/2/41](https://www.mdpi.com/2673-2688/5/2/41)  
45. Paraphrasing Techniques for Maritime QA system \- arXiv, accessed April 30, 2025, [https://arxiv.org/pdf/2203.10854](https://arxiv.org/pdf/2203.10854)  
46. Enhancing active listening skills with AI-assisted role-play \- Hyperspace, accessed April 30, 2025, [https://hyperspace.mv/enhancing-active-listening-skills-with-ai-assisted-role-playing/](https://hyperspace.mv/enhancing-active-listening-skills-with-ai-assisted-role-playing/)  
47. Incorporating Active Listening: The Best 4 Techniques \- impro.AI, accessed April 30, 2025, [https://impro.ai/incorporating-active-listening/](https://impro.ai/incorporating-active-listening/)  
48. Improving Active Listening Skills Using AI-Powered Simulations \- Hyperspace, accessed April 30, 2025, [https://hyperspace.mv/improving-active-listening-skills-using-ai-powered-simulations/](https://hyperspace.mv/improving-active-listening-skills-using-ai-powered-simulations/)  
49. Active Listening Exercises Galore\! \- Trainers Warehouse, accessed April 30, 2025, [https://blog.trainerswarehouse.com/active-listening-exercises](https://blog.trainerswarehouse.com/active-listening-exercises)  
50. Active Listening: Tips \+ Tricks to Improve Your Team's Skills, accessed April 30, 2025, [https://yoodli.ai/blog/active-listening](https://yoodli.ai/blog/active-listening)  
51. Approach to teaching active listening in the age of artificial intelligence: Lessons from the Japanese art of aizuchi \- PMC, accessed April 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11753280/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11753280/)  
52. Towards Natural Clarification Questions in Dialogue Systems \- Department of Computing, accessed April 30, 2025, [https://doc.gold.ac.uk/aisb50/AISB50-S21/AISB50-S21-Stoyanchev-paper.pdf](https://doc.gold.ac.uk/aisb50/AISB50-S21/AISB50-S21-Stoyanchev-paper.pdf)  
53. cdn.aaai.org, accessed April 30, 2025, [https://cdn.aaai.org/Symposia/Spring/2003/SS-03-06/SS03-06-006.pdf](https://cdn.aaai.org/Symposia/Spring/2003/SS-03-06/SS03-06-006.pdf)  
54. A data-driven model of explanations for a chatbot that helps to practice conversation in a foreign language \- SIGdial, accessed April 30, 2025, [https://www.sigdial.org/files/workshops/conference18/proceedings/pdf/SIGDIAL47.pdf](https://www.sigdial.org/files/workshops/conference18/proceedings/pdf/SIGDIAL47.pdf)  
55. A Survey of Conversational Search \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2410.15576v1](https://arxiv.org/html/2410.15576v1)  
56. Dense Paraphrasing for multimodal dialogue interpretation \- PMC, accessed April 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11693678/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11693678/)  
57. Dense Paraphrasing for multimodal dialogue interpretation \- Frontiers, accessed April 30, 2025, [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1479905/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1479905/full)  
58. Paraphrase Generation | Papers With Code, accessed April 30, 2025, [https://paperswithcode.com/task/paraphrase-generation/codeless?page=2](https://paperswithcode.com/task/paraphrase-generation/codeless?page=2)  
59. An Extensible and Reusable Pipeline for Automated Utterance Paraphrases \- VLDB Endowment, accessed April 30, 2025, [http://www.vldb.org/pvldb/vol14/p2839-berro.pdf](http://www.vldb.org/pvldb/vol14/p2839-berro.pdf)  
60. Reformulating Unsupervised Style Transfer as Paraphrase Generation \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2020.emnlp-main.55.pdf](https://aclanthology.org/2020.emnlp-main.55.pdf)  
61. Novel Methods for Natural Language Generation in Spoken Dialogue Systems, accessed April 30, 2025, [https://ufal.mff.cuni.cz/\~odusek/thesis/](https://ufal.mff.cuni.cz/~odusek/thesis/)  
62. Progressive campaigns | CCAI Platform \- Google Cloud, accessed April 30, 2025, [https://cloud.google.com/contact-center/ccai-platform/docs/campaign-progressive](https://cloud.google.com/contact-center/ccai-platform/docs/campaign-progressive)  
63. Progressive Summarization by Tiago Forte \- HackMD, accessed April 30, 2025, [https://hackmd.io/@\_6snqgesSRWI1ygKSv1TtA/prog-sum-doc](https://hackmd.io/@_6snqgesSRWI1ygKSv1TtA/prog-sum-doc)  
64. Progressive Summarization II: Examples and Metaphors \- Every, accessed April 30, 2025, [https://every.to/praxis/progressive-summarization-ii-examples-538088](https://every.to/praxis/progressive-summarization-ii-examples-538088)  
65. Conversation summarization in a nutshell \- Google Cloud Skills Boost, accessed April 30, 2025, [https://www.cloudskillsboost.google/paths/371/course\_templates/1102/video/491461](https://www.cloudskillsboost.google/paths/371/course_templates/1102/video/491461)  
66. Distilling from Dialogues: Finding Meaning in LLM Interactions, accessed April 30, 2025, [https://huggingface.co/blog/chansung/adaptive-summarization](https://huggingface.co/blog/chansung/adaptive-summarization)  
67. AI Summarization Techniques for Conversations | Restackio, accessed April 30, 2025, [https://www.restack.io/p/ai-summarization-answer-techniques-conversations-cat-ai](https://www.restack.io/p/ai-summarization-answer-techniques-conversations-cat-ai)  
68. Chatbots & Dialogue Systems \- Stanford University, accessed April 30, 2025, [https://web.stanford.edu/\~jurafsky/slp3/old\_dec21/24.pdf](https://web.stanford.edu/~jurafsky/slp3/old_dec21/24.pdf)  
69. A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2402.18013v1](https://arxiv.org/html/2402.18013v1)  
70. Progressive Summarization: A Practical Technique for Designing Discoverable Notes, accessed April 30, 2025, [https://fortelabs.com/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/](https://fortelabs.com/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/)  
71. Perspective Dialogue Summarization with Neural Networks \- inovex GmbH, accessed April 30, 2025, [https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/](https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/)  
72. (PDF) Conversational AI for multi-agent communication in Natural Language: Research directions at the Interaction Lab \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/363625491\_Conversational\_AI\_for\_multi-agent\_communication\_in\_Natural\_Language\_Research\_directions\_at\_the\_Interaction\_Lab](https://www.researchgate.net/publication/363625491_Conversational_AI_for_multi-agent_communication_in_Natural_Language_Research_directions_at_the_Interaction_Lab)  
73. Enhancing Incremental Summarization with Structured Representations \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2024.findings-emnlp.220/](https://aclanthology.org/2024.findings-emnlp.220/)  
74. Enhancing Empathy and Active Listening with AI Insights \- FaithGPT, accessed April 30, 2025, [https://www.faithgpt.io/blog/enhancing-empathy-and-active-listening-with-ai-insights](https://www.faithgpt.io/blog/enhancing-empathy-and-active-listening-with-ai-insights)  
75. web.stanford.edu, accessed April 30, 2025, [https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1224/reports/custom\_116987188.pdf](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1224/reports/custom_116987188.pdf)  
76. arXiv:2403.04656v2 \[cs.CL\] 9 Mar 2024, accessed April 30, 2025, [https://arxiv.org/pdf/2403.04656](https://arxiv.org/pdf/2403.04656)  
77. Towards LLM-driven Dialogue State Tracking \- OpenReview, accessed April 30, 2025, [https://openreview.net/forum?id=wDfXP6uAkR¬eId=IKo5OQk9Il](https://openreview.net/forum?id=wDfXP6uAkR&noteId=IKo5OQk9Il)  
78. Robust Dialogue State Tracking with Weak Supervision and Sparse Data \- MIT Press Direct, accessed April 30, 2025, [https://direct.mit.edu/tacl/article/doi/10.1162/tacl\_a\_00513/113662/Robust-Dialogue-State-Tracking-with-Weak](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00513/113662/Robust-Dialogue-State-Tracking-with-Weak)  
79. "Do you follow me?": A Survey of Recent Approaches in Dialogue State Tracking \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2022.sigdial-1.33.pdf](https://aclanthology.org/2022.sigdial-1.33.pdf)  
80. A Survey on Dialogue Systems: Recent Advances and New Frontiers, accessed April 30, 2025, [https://www.kdd.org/exploration\_files/19-2-Article3.pdf](https://www.kdd.org/exploration_files/19-2-Article3.pdf)  
81. "Do you follow me?": A Survey of Recent Approaches in Dialogue State Tracking \- arXiv, accessed April 30, 2025, [https://arxiv.org/abs/2207.14627](https://arxiv.org/abs/2207.14627)  
82. The Dialog State Tracking Challenge Series: A Review | Request PDF \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/346276644\_The\_Dialog\_State\_Tracking\_Challenge\_Series\_A\_Review](https://www.researchgate.net/publication/346276644_The_Dialog_State_Tracking_Challenge_Series_A_Review)  
83. Dialogue Systems Architecture Best Practices | Restackio, accessed April 30, 2025, [https://www.restack.io/p/dialogue-systems-answer-architecture-best-practices-cat-ai](https://www.restack.io/p/dialogue-systems-answer-architecture-best-practices-cat-ai)  
84. Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems, accessed April 30, 2025, [https://arxiv.org/html/2501.11613v1](https://arxiv.org/html/2501.11613v1)  
85. State Machine & Dialog Systems \- Meta-Guide.com, accessed April 30, 2025, [https://meta-guide.com/dialog-systems/state-machine-dialog-systems](https://meta-guide.com/dialog-systems/state-machine-dialog-systems)  
86. Guiding AI Conversations through Dynamic State Transitions, accessed April 30, 2025, [https://promptengineering.org/guiding-ai-conversations-through-dynamic-state-transitions/](https://promptengineering.org/guiding-ai-conversations-through-dynamic-state-transitions/)  
87. Dialogue Systems Dialog Management | Restackio, accessed April 30, 2025, [https://www.restack.io/p/dialogue-systems-answer-dialog-management-cat-ai](https://www.restack.io/p/dialogue-systems-answer-dialog-management-cat-ai)  
88. Using Large Language Models for Adaptive Dialogue Management in Digital Telephone Assistants | OpenReview, accessed April 30, 2025, [https://openreview.net/forum?id=iVhGqShgL9\&referrer=%5Bthe%20profile%20of%20Hassan%20Soliman%5D(%2Fprofile%3Fid%3D\~Hassan\_Soliman1)](https://openreview.net/forum?id=iVhGqShgL9&referrer=%5Bthe+profile+of+Hassan+Soliman%5D\(/profile?id%3D~Hassan_Soliman1\))  
89. A Neural Network Approach to Intention Modeling for User-Adapted ..., accessed April 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC4706878/](https://pmc.ncbi.nlm.nih.gov/articles/PMC4706878/)  
90. Adaptive Spoken Dialogue Systems \- CiteSeerX, accessed April 30, 2025, [https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=6ce073bd6e5e397f6e8f0e7823874bad05893c74](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=6ce073bd6e5e397f6e8f0e7823874bad05893c74)  
91. Adaptive dialogue management using intent clustering and fuzzy rules \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/345845411\_Adaptive\_dialogue\_management\_using\_intent\_clustering\_and\_fuzzy\_rules](https://www.researchgate.net/publication/345845411_Adaptive_dialogue_management_using_intent_clustering_and_fuzzy_rules)  
92. Controllable Mixed-Initiative Dialogue Generation through ..., accessed April 30, 2025, [https://aclanthology.org/2023.acl-short.82/](https://aclanthology.org/2023.acl-short.82/)  
93. Enhancing Conversational AI with Reinforcement Learning for Multi-turn Dialogue Management, accessed April 30, 2025, [https://www.seejph.com/index.php/seejph/article/download/4207/2779/6413](https://www.seejph.com/index.php/seejph/article/download/4207/2779/6413)  
94. Unlocking Conversational AI: Reinforcement Learning for Natural Language Processing in Dialogue Management \- 30 Days Coding, accessed April 30, 2025, [https://30dayscoding.com/blog/reinforcement-learning-natural-language-processing-dialogue-management](https://30dayscoding.com/blog/reinforcement-learning-natural-language-processing-dialogue-management)  
95. Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System, accessed April 30, 2025, [https://web.eecs.umich.edu/\~baveja/Papers/RLDSjair.pdf](https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf)  
96. Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue, accessed April 30, 2025, [https://arxiv.org/html/2406.14457v1](https://arxiv.org/html/2406.14457v1)  
97. aclanthology.org, accessed April 30, 2025, [https://aclanthology.org/2024.findings-emnlp.472.pdf](https://aclanthology.org/2024.findings-emnlp.472.pdf)  
98. Deep Reinforcement Learning for Task-Oriented Dialogue, accessed April 30, 2025, [https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/custom/15842265.pdf](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/custom/15842265.pdf)  
99. Interactive reinforcement learning for task-oriented dialogue management \- Google Research, accessed April 30, 2025, [https://research.google.com/pubs/archive/45734.pdf](https://research.google.com/pubs/archive/45734.pdf)  
100. aclanthology.org, accessed April 30, 2025, [https://aclanthology.org/D19-1010.pdf](https://aclanthology.org/D19-1010.pdf)  
101. A CASE STUDY ON REWARD LEARNING FOR TASK- ORIENTED DIALOGUE SYSTEMS \- OpenReview, accessed April 30, 2025, [https://openreview.net/pdf?id=086pmarAris](https://openreview.net/pdf?id=086pmarAris)  
102. A CASE STUDY ON REWARD LEARNING FOR TASK- ORIENTED DIALOGUE SYSTEMS \- OpenReview, accessed April 30, 2025, [https://openreview.net/pdf?id=YaEgoWIxwvk](https://openreview.net/pdf?id=YaEgoWIxwvk)  
103. arXiv:2307.06721v1 \[cs.CL\] 13 Jul 2023, accessed April 30, 2025, [https://arxiv.org/pdf/2307.06721](https://arxiv.org/pdf/2307.06721)  
104. arXiv:2204.08426v1 \[cs.CL\] 18 Apr 2022, accessed April 30, 2025, [https://arxiv.org/pdf/2204.08426](https://arxiv.org/pdf/2204.08426)  
105. BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems \- AAAI, accessed April 30, 2025, [https://cdn.aaai.org/ojs/11946/11946-13-15474-1-2-20201228.pdf](https://cdn.aaai.org/ojs/11946/11946-13-15474-1-2-20201228.pdf)  
106. Rescue Conversations from Dead-ends: Efficient Exploration for Task-oriented Dialogue Policy Optimization | Transactions of the Association for Computational Linguistics \- MIT Press Direct, accessed April 30, 2025, [https://direct.mit.edu/tacl/article/doi/10.1162/tacl\_a\_00717/125484/Rescue-Conversations-from-Dead-ends-Efficient](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00717/125484/Rescue-Conversations-from-Dead-ends-Efficient)  
107. KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning | OpenReview, accessed April 30, 2025, [https://openreview.net/forum?id=EY9k2x5qWB\&referrer=%5Bthe%20profile%20of%20Zhou%20Yu%5D(%2Fprofile%3Fid%3D\~Zhou\_Yu1)](https://openreview.net/forum?id=EY9k2x5qWB&referrer=%5Bthe+profile+of+Zhou+Yu%5D\(/profile?id%3D~Zhou_Yu1\))  
108. A Survey on Recent Advances and Challenges in Reinforcement Learning Methods for Task-oriented Dialogue Policy Learning \- Machine Intelligence Research, accessed April 30, 2025, [https://www.mi-research.net/article/doi/10.1007/s11633-022-1347-y](https://www.mi-research.net/article/doi/10.1007/s11633-022-1347-y)  
109. \[2202.13675\] A Survey on Recent Advances and Challenges in Reinforcement Learning Methods for Task-Oriented Dialogue Policy Learning \- arXiv, accessed April 30, 2025, [https://arxiv.org/abs/2202.13675](https://arxiv.org/abs/2202.13675)  
110. Goal Shaping for Efficient Task-oriented Dialogue Policy Learning \- IFAAMAS, accessed April 30, 2025, [https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p2615.pdf](https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p2615.pdf)  
111. GitHub \- ruleGreen/Survey-Evolution-DS: This is the repo which record the evolution of LM-based dialogue system. More details can be found in our original survey paper, accessed April 30, 2025, [https://github.com/ruleGreen/Survey-Evolution-DS](https://github.com/ruleGreen/Survey-Evolution-DS)  
112. Context-Aware AI for Dialogue Systems | Restackio, accessed April 30, 2025, [https://www.restack.io/p/dialogue-management-answer-context-aware-ai-cat-ai](https://www.restack.io/p/dialogue-management-answer-context-aware-ai-cat-ai)  
113. A Context-Aware Character Dialog System \- GDC Vault, accessed April 30, 2025, [https://gdcvault.com/play/1020386/A-Context-Aware-Character-Dialog](https://gdcvault.com/play/1020386/A-Context-Aware-Character-Dialog)  
114. Contextual topic modeling for dialogue systems \- Amazon Science, accessed April 30, 2025, [https://www.amazon.science/publications/contextual-topic-modeling-for-dialogue-systems](https://www.amazon.science/publications/contextual-topic-modeling-for-dialogue-systems)  
115. Chat Dialogue System with Context Understanding | NTT Technical Review, accessed April 30, 2025, [https://www.ntt-review.jp/archive/ntttechnical.php?contents=ntr201911fa5\_s.html](https://www.ntt-review.jp/archive/ntttechnical.php?contents=ntr201911fa5_s.html)  
116. The Complete Guide To AI Turn-Taking | 2025 \- Tavus, accessed April 30, 2025, [https://www.tavus.io/post/ai-turn-taking](https://www.tavus.io/post/ai-turn-taking)  
117. Mixed-initiative interaction \- Microsoft, accessed April 30, 2025, [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/mixedinit.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/mixedinit.pdf)  
118. Conversation Design \- Cooperative Principle \- Google for Developers, accessed April 30, 2025, [https://developers.google.com/assistant/conversation-design/learn-about-conversation](https://developers.google.com/assistant/conversation-design/learn-about-conversation)  
119. Applying General Turn-taking Models to Conversational Human-Robot Interaction \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2501.08946v1](https://arxiv.org/html/2501.08946v1)  
120. VAD vs. Turn-Taking Endpoints in Conversational AI \- Retell AI, accessed April 30, 2025, [https://www.retellai.com/blog/vad-vs-turn-taking-end-point-in-conversational-ai](https://www.retellai.com/blog/vad-vs-turn-taking-end-point-in-conversational-ai)  
121. Language Models in Dialogue: Conversational Maxims for Human-AI Interactions \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2403.15115v1](https://arxiv.org/html/2403.15115v1)  
122. 7 Principles of Conversational Design for Virtual Assistants \- KeyReply, accessed April 30, 2025, [https://www.keyreply.com/blog/conversational-design-virtual-assistants](https://www.keyreply.com/blog/conversational-design-virtual-assistants)  
123. The Gricean Maxims in NLP \- A Survey \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2024.inlg-main.39.pdf](https://aclanthology.org/2024.inlg-main.39.pdf)  
124. many faces of a chatbot: the use of positive and negative politeness strategies in argumentative communication with a chatbot \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/387492138\_MANY\_FACES\_OF\_A\_CHATBOT\_THE\_USE\_OF\_POSITIVE\_AND\_NEGATIVE\_POLITENESS\_STRATEGIES\_IN\_ARGUMENTATIVE\_COMMUNICATION\_WITH\_A\_CHATBOT](https://www.researchgate.net/publication/387492138_MANY_FACES_OF_A_CHATBOT_THE_USE_OF_POSITIVE_AND_NEGATIVE_POLITENESS_STRATEGIES_IN_ARGUMENTATIVE_COMMUNICATION_WITH_A_CHATBOT)  
125. Investigating politeness strategies in chatbots through the lens of Conversation Analysis | Request PDF \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/377687496\_Investigating\_politeness\_strategies\_in\_chatbots\_through\_the\_lens\_of\_Conversation\_Analysis](https://www.researchgate.net/publication/377687496_Investigating_politeness_strategies_in_chatbots_through_the_lens_of_Conversation_Analysis)  
126. Exploring how politeness impacts the user experience of chatbots ..., accessed April 30, 2025, [https://www.microsoft.com/en-us/research/publication/exploring-how-politeness-impacts-the-user-experience-of-chatbots-for-mental-health-support/](https://www.microsoft.com/en-us/research/publication/exploring-how-politeness-impacts-the-user-experience-of-chatbots-for-mental-health-support/)  
127. Engaging with AI: How Interface Design Shapes Human-AI Collaboration in High-Stakes Decision-Making \- arXiv, accessed April 30, 2025, [https://arxiv.org/pdf/2501.16627?](https://arxiv.org/pdf/2501.16627)  
128. Engaging with AI: How Interface Design Shapes Human-AI Collaboration in High-Stakes Decision-Making \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/388460287\_Engaging\_with\_AI\_How\_Interface\_Design\_Shapes\_Human-AI\_Collaboration\_in\_High-Stakes\_Decision-Making](https://www.researchgate.net/publication/388460287_Engaging_with_AI_How_Interface_Design_Shapes_Human-AI_Collaboration_in_High-Stakes_Decision-Making)  
129. A Design Space for Intelligent Dialogue Augmentation \- IVIA Lab Resources, accessed April 30, 2025, [https://cdn.ivia.ch/publications/pdf/2025chandesign.pdf](https://cdn.ivia.ch/publications/pdf/2025chandesign.pdf)  
130. What is Cognitive Load? | IxDF, accessed April 30, 2025, [https://www.interaction-design.org/literature/topics/cognitive-load](https://www.interaction-design.org/literature/topics/cognitive-load)  
131. Active Listening: Transform Feedback Collection | InMoment, accessed April 30, 2025, [https://inmoment.com/blog/active-listening-for-feedback-collection/](https://inmoment.com/blog/active-listening-for-feedback-collection/)  
132. AI Voice Agents: Enhancing Customer Support with Conversational AI \- POWR Blog, accessed April 30, 2025, [https://blog.powr.io/ai-voice-agents-enhancing-customer-support-with-conversational-ai](https://blog.powr.io/ai-voice-agents-enhancing-customer-support-with-conversational-ai)  
133. Slot Filling | Papers With Code, accessed April 30, 2025, [https://paperswithcode.com/task/slot-filling/codeless?page=14](https://paperswithcode.com/task/slot-filling/codeless?page=14)  
134. HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals \- arXiv, accessed April 30, 2025, [https://arxiv.org/html/2411.07152v1](https://arxiv.org/html/2411.07152v1)  
135. Proceedings of the 31st International Conference on Computational Linguistics: Industry Track \- ACL Anthology, accessed April 30, 2025, [https://aclanthology.org/2025.coling-industry.0.pdf](https://aclanthology.org/2025.coling-industry.0.pdf)  
136. Four Design Patterns for Event-Driven, Multi-Agent Systems \- Confluent, accessed April 30, 2025, [https://www.confluent.io/blog/event-driven-multi-agent-systems/](https://www.confluent.io/blog/event-driven-multi-agent-systems/)  
137. Using AI for requirements analysis: A case study | Thoughtworks United States, accessed April 30, 2025, [https://www.thoughtworks.com/en-us/insights/blog/generative-ai/using-ai-requirements-analysis-case-study](https://www.thoughtworks.com/en-us/insights/blog/generative-ai/using-ai-requirements-analysis-case-study)  
138. AI Meets Requirements Management: A Game-Changer for Tech Projects \- Opteamix, accessed April 30, 2025, [https://opteamix.com/ai-meets-requirements-management-a-game-changer-for-tech-projects/](https://opteamix.com/ai-meets-requirements-management-a-game-changer-for-tech-projects/)  
139. How AI is Transforming Requirements Gathering and Documentation \- Copilot4DevOps, accessed April 30, 2025, [https://copilot4devops.com/ai-in-requirements-gathering-and-documentation/](https://copilot4devops.com/ai-in-requirements-gathering-and-documentation/)  
140. How AI is automating requirement gathering in 2024 \- IoT Tech News, accessed April 30, 2025, [https://iottechnews.com/news/how-ai-is-automating-requirement-gathering-in-2024/](https://iottechnews.com/news/how-ai-is-automating-requirement-gathering-in-2024/)  
141. Top 10 AI Tools for Requirements Gathering Success in 2025, accessed April 30, 2025, [https://clickup.com/blog/ai-tools-for-requirements-gathering/](https://clickup.com/blog/ai-tools-for-requirements-gathering/)  
142. Leveraging Artificial Intelligence in Requirements Management \- Jama Software, accessed April 30, 2025, [https://www.jamasoftware.com/blog/leveraging-artificial-intelligence-in-requirements-management/](https://www.jamasoftware.com/blog/leveraging-artificial-intelligence-in-requirements-management/)  
143. Prioritizing with MOSCOW: AI-Assisted Qualitative Analysis for Requirements Gathering, accessed April 30, 2025, [https://insight7.io/prioritizing-with-moscow-ai-assisted-qualitative-analysis-for-requirements-gathering/](https://insight7.io/prioritizing-with-moscow-ai-assisted-qualitative-analysis-for-requirements-gathering/)  
144. How We Use AI to Write Requirements \- ArgonDigital | Making Technology a Strategic Advantage, accessed April 30, 2025, [https://argondigital.com/blog/general/how-we-use-ai-to-write-requirements/](https://argondigital.com/blog/general/how-we-use-ai-to-write-requirements/)  
145. AI to support requirement gathering and analysis : r/AIBizOps \- Reddit, accessed April 30, 2025, [https://www.reddit.com/r/AIBizOps/comments/1axvfdr/ai\_to\_support\_requirement\_gathering\_and\_analysis/](https://www.reddit.com/r/AIBizOps/comments/1axvfdr/ai_to_support_requirement_gathering_and_analysis/)  
146. Can AI Really Write Your User Requirements? Conversation with Chris Rickard, creator of Userdoc \- YouTube, accessed April 30, 2025, [https://www.youtube.com/watch?v=yvJtG5Gji8A\&pp=0gcJCdgAo7VqN5tD](https://www.youtube.com/watch?v=yvJtG5Gji8A&pp=0gcJCdgAo7VqN5tD)  
147. Conversational Elicitation Techniques \- Squarespace, accessed April 30, 2025, [https://static1.squarespace.com/static/55eb4adbe4b097dd68b32ba4/t/607efa6db83093372a3c886f/1618934382056/Deena+-+FBI+Elicitation+Techniques.pdf](https://static1.squarespace.com/static/55eb4adbe4b097dd68b32ba4/t/607efa6db83093372a3c886f/1618934382056/Deena+-+FBI+Elicitation+Techniques.pdf)  
148. The Top 5 Elicitation Techniques Used By Business Analysts \- Bridging the Gap, accessed April 30, 2025, [https://www.bridging-the-gap.com/elicitation-techniques-business-analysts/](https://www.bridging-the-gap.com/elicitation-techniques-business-analysts/)  
149. Requirements Gathering Like an FBI Agent: Real-World Examples | Apex Systems, accessed April 30, 2025, [https://www.apexsystems.com/insights/article/requirements-gathering-fbi-agent-real-world-examples](https://www.apexsystems.com/insights/article/requirements-gathering-fbi-agent-real-world-examples)  
150. Requirement Elicitation: Definition, Importance & Methods \- The Knowledge Academy, accessed April 30, 2025, [https://www.theknowledgeacademy.com/blog/requirement-elicitation/](https://www.theknowledgeacademy.com/blog/requirement-elicitation/)  
151. Requirements Elicitation in Cognitive Service for Conversational Recommendation \- arXiv, accessed April 30, 2025, [https://arxiv.org/pdf/2203.14958](https://arxiv.org/pdf/2203.14958)  
152. Designing a conversational requirements elicitation system for end-users \- KIT, accessed April 30, 2025, [https://publikationen.bibliothek.kit.edu/1000096482/64959330](https://publikationen.bibliothek.kit.edu/1000096482/64959330)  
153. REQUIREMENTS ELICITATION TECHNIQUES \- YouTube, accessed April 30, 2025, [https://www.youtube.com/watch?v=uQQAiCXqnk0](https://www.youtube.com/watch?v=uQQAiCXqnk0)  
154. 2 Requirements Elicitation: A Survey of Techniques, Approaches, and Tools, accessed April 30, 2025, [https://web.eecs.umich.edu/\~weimerw/2022-481W/readings/requirements.pdf](https://web.eecs.umich.edu/~weimerw/2022-481W/readings/requirements.pdf)  
155. Designing a Conversational Requirements Elicitation System for End-Users \- ResearchGate, accessed April 30, 2025, [https://www.researchgate.net/publication/337788381\_Designing\_a\_Conversational\_Requirements\_Elicitation\_System\_for\_End-Users](https://www.researchgate.net/publication/337788381_Designing_a_Conversational_Requirements_Elicitation_System_for_End-Users)  
156. Top Conversational AI Examples and Use Cases—How It Works, accessed April 30, 2025, [https://www.rezolve.ai/blog/conversational-ai-examples-use-cases-for-modern-it-support](https://www.rezolve.ai/blog/conversational-ai-examples-use-cases-for-modern-it-support)  
157. 12 Real-world Chatbot Examples in 2025 \- DevRev, accessed April 30, 2025, [https://devrev.ai/blog/chatbot-examples](https://devrev.ai/blog/chatbot-examples)  
158. 5 Beautiful Chatbot UI Examples That'll Inspire You \- Voiceflow, accessed April 30, 2025, [https://www.voiceflow.com/blog/chatbot-ui](https://www.voiceflow.com/blog/chatbot-ui)  
159. Free Access Reinforcement Learning For Adaptive Dialogue Systems A Data Driven Methodology For Dialogue Management And Natural L \- NYU, accessed April 30, 2025, [https://staging.entrepreneur.nyu.edu/xinjured/grunj/vembodyu/71502243/reinforcement+learning+for+adaptive+dialogue+systems+a+data+driven+methodology+for+dialogue+management+and+natural+language+generation+theory+and+applications+of+natural+language+processing.pdf](https://staging.entrepreneur.nyu.edu/xinjured/grunj/vembodyu/71502243/reinforcement+learning+for+adaptive+dialogue+systems+a+data+driven+methodology+for+dialogue+management+and+natural+language+generation+theory+and+applications+of+natural+language+processing.pdf)  
160. Full article: A case-based approach to dialogue systems, accessed April 30, 2025, [https://www.tandfonline.com/doi/full/10.1080/09528130902723708?scroll=top\&needAccess=true](https://www.tandfonline.com/doi/full/10.1080/09528130902723708?scroll=top&needAccess=true)  
161. A Student-Teacher Architecture for Dialog Domain Adaptation Under the Meta-Learning Setting, accessed April 30, 2025, [https://ojs.aaai.org/index.php/AAAI/article/view/17614/17421](https://ojs.aaai.org/index.php/AAAI/article/view/17614/17421)  
162. An Agent-Based Dialog System for Adaptive and Multimodal Interface: A Case Study, accessed April 30, 2025, [https://www.researchgate.net/publication/272004405\_An\_Agent-Based\_Dialog\_System\_for\_Adaptive\_and\_Multimodal\_Interface\_A\_Case\_Study](https://www.researchgate.net/publication/272004405_An_Agent-Based_Dialog_System_for_Adaptive_and_Multimodal_Interface_A_Case_Study)  
163. What is conversational AI: Benefits and applications | SAP, accessed April 30, 2025, [https://www.sap.com/norway/resources/what-is-conversational-ai](https://www.sap.com/norway/resources/what-is-conversational-ai)  
164. Top 17 Conversational AI Use Cases & Benefits \- CHI Software, accessed April 30, 2025, [https://chisw.com/blog/conversational-ai-applications-use-cases/](https://chisw.com/blog/conversational-ai-applications-use-cases/)