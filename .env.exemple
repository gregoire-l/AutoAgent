# AutoAgent V1 Environment Variables Example
# Copy this file to .env and fill in your actual values.

# --- Port Configuration ---
# External ports for services. Ensure these are free on your host machine.
GO_CORE_PORT=8080
PYTHON_IA_PORT=50051
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687
TEMPORAL_UI_PORT=8088
MINIO_API_PORT=9000
MINIO_CONSOLE_PORT=9001
E2B_SANDBOX_PORT=3000 # Example, if self-hosting E2B and it exposes a port

# --- Neo4j Configuration ---
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_strong_neo4j_password # Change this!
# Internal Neo4j Bolt URL used by services within the Docker network
NEO4J_BOLT_URL=bolt://neo4j:7687

# --- MinIO Configuration ---
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=your_strong_minio_password # Change this!
# Internal MinIO S3 Endpoint used by services within the Docker network
MINIO_ENDPOINT=http://minio:9000

# --- Temporal Configuration ---
# Temporal gRPC endpoint for worker connections within the Docker network
TEMPORAL_GRPC_ENDPOINT=temporal:7233

# --- E2B Sandbox Configuration ---
# API Key for E2B (if using their cloud service)
E2B_API_KEY=your_e2b_api_key_here # Obtain from E2B website
# URL for E2B Sandbox (if self-hosting or using a specific endpoint)
# For cloud, it's managed by their SDK. For self-hosted, it might be:
E2B_SANDBOX_URL=http://e2b-sandbox:3000 # Example for self-hosted on Docker network

# --- LLM Provider Configuration ---
# Generic API Key for your chosen LLM Provider (e.g., OpenAI, Anthropic, etc.)
# The specific provider and model will be configured within the python-ia service.
LLM_PROVIDER_API_KEY_GENERIC=your_llm_provider_api_key_here

# --- Service-Specific Configuration (Optional) ---
# Example: Log level for go-core
# GO_CORE_LOG_LEVEL=debug

# Example: Default model for python-ia
# PYTHON_IA_DEFAULT_MODEL=gpt-4

# --- Docker Network Configuration (Informational - managed by docker-compose) ---
# DOCKER_NETWORK_NAME=autoagent-net
